{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms.v2.functional as F_v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from Utils.dataset import PreloadedDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from Deep_Learning.Representation_Learning.Methods.AugPC.train import train as train_augpc\n",
    "from Deep_Learning.Representation_Learning.Methods.AugPC.model import AugPC\n",
    "from Deep_Learning.Representation_Learning.Methods.LAugPC.train import train as train_laugpc\n",
    "from Deep_Learning.Representation_Learning.Methods.LAugPC.model import LAugPC\n",
    "from Deep_Learning.Representation_Learning.Methods.BYOL.train import train as train_byol\n",
    "from Deep_Learning.Representation_Learning.Methods.BYOL.model import BYOL\n",
    "from Deep_Learning.Representation_Learning.Methods.SimCLR.train import train as train_simclr\n",
    "from Deep_Learning.Representation_Learning.Methods.SimCLR.model import SimCLR\n",
    "\n",
    "from Deep_Learning.Representation_Learning.Evals.mnist1k_linear import mnist1k_linear_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST(root='../Datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "t_dataset = datasets.MNIST(root='../Datasets/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "VAL_RATIO = 0.2\n",
    "n_val = int(len(dataset) * VAL_RATIO)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # SigmoidTransform(),\n",
    "    # TanhTransform(),\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # SigmoidTransform(),\n",
    "    # TanhTransform()\n",
    "])\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomCrop(20),\n",
    "    transforms.Resize(28, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    # transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "])\n",
    "\n",
    "train_set = PreloadedDataset.from_dataset(train_set, train_transform, device)\n",
    "val_set = PreloadedDataset.from_dataset(val_set, val_transform, device)\n",
    "test_set = PreloadedDataset.from_dataset(t_dataset, val_transform, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: tensor(1., device='cuda:0')\n",
      "Min value: tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Show example images\n",
    "fig, axes = plt.subplots(1, 10, figsize=(15,5))\n",
    "for i, ax in enumerate(axes):\n",
    "    img, label = train_set[i]\n",
    "    angle = torch.rand(1).item() * 360 - 180 if torch.rand(1).item() > 0.75 else 0\n",
    "    translate_x = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "    translate_y = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "    scale = torch.rand(1).item() * 0.5 + 0.75 if torch.rand(1).item() > 0.75 else 1.0\n",
    "    shear = torch.rand(1).item() * 50 - 25 if torch.rand(1).item() > 0.75 else 0\n",
    "    img = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "    ax.imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    ax.set_title(f\"Label: {label}\")\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# print max and min values\n",
    "print('Max value:', train_set.transformed_images.max())\n",
    "print('Min value:', train_set.transformed_images.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = SimCLR\n",
    "backbone = 'alexnet'\n",
    "model_name = f'{Model.__name__}-{backbone}'\n",
    "log_dir = f'Deep_Learning/Representation_Learning/out/logs/{model_name}/'\n",
    "save_dir = f'Deep_Learning/Representation_Learning/out/models/{model_name}.pth'\n",
    "# log_dir = None\n",
    "# save_dir = None\n",
    "model = Model(in_features=1, backbone=backbone).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found, training new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [0/500]:   0%|          | 0/188 [00:00<?, ?it/s]c:\\Users\\joeag\\Documents\\ml-learning\\Deep_Learning\\Representation_Learning\\SimCLR\\lars.py:92: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1485.)\n",
      "  p.data.add_(-local_lr * group['lr'], d_p)\n",
      "                                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 63\u001b[0m\n\u001b[0;32m     18\u001b[0m     writer \u001b[38;5;241m=\u001b[39m SummaryWriter(log_dir)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# train_augpc(\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#     model,\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#     train_set,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m#     save_every=5,\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m \u001b[43mtrain_simclr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugmentation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\ml-learning\\Deep_Learning\\Representation_Learning\\SimCLR\\train.py:62\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataset, val_dataset, num_epochs, batch_size, lr, wd, temperature, augmentation, writer, save_dir, save_every)\u001b[0m\n\u001b[0;32m     59\u001b[0m     loss \u001b[38;5;241m=\u001b[39m NTXent(z, temperature)\n\u001b[0;32m     61\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 62\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimiser)\n\u001b[0;32m     64\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "to_train = True\n",
    "if save_dir is not None:\n",
    "    try:\n",
    "        sd = torch.load(save_dir)\n",
    "        # change keys \"project\" to \"transition\"\n",
    "        for key in list(sd.keys()):\n",
    "            if 'project' in key:\n",
    "                sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "        model.load_state_dict(sd)\n",
    "        to_train = False\n",
    "        print('Model loaded successfully')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "        print('Model not found, training new model')\n",
    "if to_train:\n",
    "    writer = None\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(log_dir)\n",
    "    # train_augpc(\n",
    "    #     model,\n",
    "    #     train_set,\n",
    "    #     val_set,\n",
    "    #     num_epochs=500,\n",
    "    #     batch_size=128,\n",
    "    #     lr=3e-4,\n",
    "    #     wd=1.5e-6,\n",
    "    #     writer=writer,\n",
    "    #     save_dir=save_dir,\n",
    "    #     save_every=5,\n",
    "    #     aug_scaler='none'\n",
    "    # )\n",
    "\n",
    "    # train_laugpc(\n",
    "    #     model,\n",
    "    #     train_set,\n",
    "    #     val_set,\n",
    "    #     num_epochs=250,\n",
    "    #     batch_size=256,\n",
    "    #     lr=0.001,\n",
    "    #     wd=0.02,\n",
    "    #     beta=0.996,\n",
    "    #     writer=writer,\n",
    "    #     save_dir=save_dir,\n",
    "    #     save_every=5,\n",
    "    # )\n",
    "\n",
    "\n",
    "    # train_byol(\n",
    "    #     model,\n",
    "    #     train_set,\n",
    "    #     val_set,\n",
    "    #     num_epochs=500,\n",
    "    #     batch_size=256,\n",
    "    #     lr=3e-4,\n",
    "    #     wd=1.5e-6,\n",
    "    #     augmentation=augmentation,\n",
    "    #     beta=0.996,\n",
    "    #     writer=writer,\n",
    "    #     save_dir=save_dir,\n",
    "    #     save_every=5,\n",
    "    # )\n",
    "\n",
    "    train_simclr(\n",
    "        model,\n",
    "        train_set,\n",
    "        val_set,\n",
    "        num_epochs=500,\n",
    "        batch_size=256,\n",
    "        lr=3e-4,\n",
    "        wd=0.0,\n",
    "        temperature=1.0,\n",
    "        augmentation=augmentation,\n",
    "        writer=writer,\n",
    "        save_dir=save_dir,\n",
    "        save_every=5,\n",
    "    )\n",
    "\n",
    "    print(f'Finished training')\n",
    "    if save_dir is not None:\n",
    "        print('Run cell again to load best (val_acc) model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 0.9797999858856201\n"
     ]
    }
   ],
   "source": [
    "# collect 100 of each target index from train_set.targets\n",
    "writer = SummaryWriter(log_dir)\n",
    "mnist1k_linear_eval(model, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f950b8bf675c458bb9a3d5687495816a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='angle', max=180, min=-180), IntSlider(value=0, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.compare(model, img, angle, translate_x, translate_y, scale, shear)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = train_set[4][0].unsqueeze(0)\n",
    "model.eval()\n",
    "\n",
    "def compare(model, img, angle, translate_x, translate_y, scale, shear):\n",
    "    img_aug = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "    action = torch.tensor([angle/180, translate_x/8, translate_y/8, (scale-1.0)/0.25, shear/25], dtype=torch.float32, device=img.device).unsqueeze(0).repeat(img.shape[0], 1)\n",
    "    img_pred = model.predict(img, action)\n",
    "    loss = F.mse_loss(img_aug, img_pred)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
    "    axes[0].imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(img_aug.squeeze().cpu(), cmap='gray')\n",
    "    axes[1].set_title('Augmented')\n",
    "    axes[1].axis('off')\n",
    "    axes[2].imshow(img_pred.squeeze().cpu().detach(), cmap='gray')\n",
    "    axes[2].set_title('Predicted')\n",
    "    axes[2].axis('off')\n",
    "    plt.show()\n",
    "    return loss.item()\n",
    "\n",
    "interact(compare, model=fixed(model), img=fixed(img), angle=(-180, 180), translate_x=(-8, 8), translate_y=(-8, 8), scale=(0.75, 1.25), shear=(-25, 25))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
