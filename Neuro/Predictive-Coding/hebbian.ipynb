{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "U1 = nn.Linear(2,4, bias=False)\n",
    "U2 = nn.Linear(4,6, bias=False)\n",
    "\n",
    "def step(x, e1, r1, e2, r2):\n",
    "    with torch.no_grad():\n",
    "        e1 = x - torch.matmul(U1.weight.T, r1)\n",
    "    r1 = r1 + U1(e1) \n",
    "    with torch.no_grad():\n",
    "        r1 -= (0.01*e2)\n",
    "        e2 = r1 - torch.matmul(U2.weight.T, r2)\n",
    "    r2 = r2 + U2(e2)\n",
    "    return e1, r1, e2, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2)\n",
    "e1 = torch.rand(2)\n",
    "r1 = torch.rand(4)\n",
    "e2 = torch.rand(4)\n",
    "r2 = torch.rand(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: tensor([0.8860, 0.5832])\n",
      "e1: tensor([ 0.1565, -0.0101])\n",
      "r1: tensor([ 1.2042,  0.1495,  0.1594, -0.5727], grad_fn=<AddBackward0>)\n",
      "e2: tensor([ 0.2313,  0.3016, -0.1143, -0.4969])\n",
      "r2: tensor([ 0.4809,  1.0673,  1.1476, -0.4755,  0.2951,  0.0814],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "e1 = e1.detach()\n",
    "r1 = r1.detach()\n",
    "e2 = e2.detach()\n",
    "r2 = r2.detach()\n",
    "e1, r1, e2, r2 = step(x, e1, r1, e2, r2)\n",
    "print(f\" x: {x}\")\n",
    "print(f\"e1: {e1}\")\n",
    "print(f\"r1: {r1}\")\n",
    "print(f\"e2: {e2}\")\n",
    "print(f\"r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U1.weight.grad:\n",
      "tensor([[ 0.1884, -0.0122],\n",
      "        [ 0.0234, -0.0015],\n",
      "        [ 0.0249, -0.0016],\n",
      "        [-0.0896,  0.0058]])\n",
      "U2.weight.grad:\n",
      "tensor([[ 0.1112,  0.1451, -0.0550, -0.2390],\n",
      "        [ 0.2468,  0.3219, -0.1220, -0.5303],\n",
      "        [ 0.2654,  0.3462, -0.1312, -0.5702],\n",
      "        [-0.1100, -0.1434,  0.0544,  0.2363],\n",
      "        [ 0.0682,  0.0890, -0.0337, -0.1466],\n",
      "        [ 0.0188,  0.0246, -0.0093, -0.0405]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    U1.weight.grad = torch.zeros_like(U1.weight)\n",
    "    U2.weight.grad = torch.zeros_like(U2.weight)\n",
    "loss = 0.5*((r1**2).sum() + (r2**2).sum())\n",
    "loss.sum().backward()\n",
    "print(f'U1.weight.grad:\\n{U1.weight.grad}')\n",
    "print(f'U2.weight.grad:\\n{U2.weight.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\n",
      "tensor([[ 0.1884, -0.0122],\n",
      "        [ 0.0234, -0.0015],\n",
      "        [ 0.0249, -0.0016],\n",
      "        [-0.0896,  0.0058]], grad_fn=<PermuteBackward0>)\n",
      "2:\n",
      "tensor([[ 0.1112,  0.1451, -0.0550, -0.2390],\n",
      "        [ 0.2468,  0.3219, -0.1220, -0.5303],\n",
      "        [ 0.2654,  0.3462, -0.1312, -0.5702],\n",
      "        [-0.1100, -0.1434,  0.0544,  0.2363],\n",
      "        [ 0.0682,  0.0890, -0.0337, -0.1466],\n",
      "        [ 0.0188,  0.0246, -0.0093, -0.0405]], grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'1:\\n{torch.matmul(e1.unsqueeze(1), r1.unsqueeze(1).T).T}')\n",
    "print(f'2:\\n{torch.matmul(e2.unsqueeze(1), r2.unsqueeze(1).T).T}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = nn.Conv2d(1, 3, (3,3), bias=False)\n",
    "optimiser = torch.optim.SGD(U.parameters(), lr=0.001)\n",
    "Ut = nn.ConvTranspose2d(3, 1, (3,3))\n",
    "with torch.no_grad():\n",
    "    Ut.weight = U.weight\n",
    "grad = torch.zeros_like(U.weight)\n",
    "def step(x, e, r):\n",
    "    with torch.no_grad():\n",
    "        e = x - Ut(r)\n",
    "    r = r + U(e)\n",
    "    return e, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1,1,4,4))\n",
    "e = torch.zeros_like(x)\n",
    "r = torch.zeros((1,3,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.5686, -0.0906,  0.0353,  0.2347],\n",
      "          [ 0.3378,  0.1243, -0.1070, -0.0324],\n",
      "          [ 0.2056,  0.1212, -0.0081, -0.0222],\n",
      "          [ 0.0375,  0.0403,  0.0899,  0.0199]]]])\n",
      "tensor([[[[ 0.3041,  0.3235],\n",
      "          [-0.1773, -0.0444]],\n",
      "\n",
      "         [[-0.0907, -1.0017],\n",
      "          [ 0.0183, -0.6439]],\n",
      "\n",
      "         [[ 0.6487,  1.1892],\n",
      "          [-0.4736, -0.6325]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "e = e.detach()\n",
    "r = r.detach()\n",
    "e, r = step(x, e, r)\n",
    "print(e)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0582, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimiser.zero_grad()\n",
    "loss = (0.5*(r**2)).sum()\n",
    "print(loss)\n",
    "loss.backward()\n",
    "optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0782, -0.0334,  0.1071],\n",
       "          [ 0.1011, -0.0180, -0.0406],\n",
       "          [ 0.0933,  0.0231, -0.0265]]],\n",
       "\n",
       "\n",
       "        [[[-0.0347,  0.0440, -0.2194],\n",
       "          [-0.2294,  0.1033,  0.0563],\n",
       "          [-0.1653, -0.0601,  0.0118]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0226, -0.0079,  0.3732],\n",
       "          [ 0.1929, -0.0989, -0.0901],\n",
       "          [ 0.2343, -0.0069, -0.0868]]]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.weight.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
