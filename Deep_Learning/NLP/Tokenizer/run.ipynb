{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive Processing is a process theory for the neocortex. It posits that the brain makes use of generative model in order to solve the inverse problem of perception, that is, inferring the causes of sensory observations\n",
      "length: 222\n",
      "[80, 114, 101, 100, 105, 99, 116, 105, 118, 101, 32, 80, 114, 111, 99, 101, 115, 115, 105, 110, 103, 32, 105, 115, 32, 97, 32, 112, 114, 111, 99, 101, 115, 115, 32, 116, 104, 101, 111, 114, 121, 32, 102, 111, 114, 32, 116, 104, 101, 32, 110, 101, 111, 99, 111, 114, 116, 101, 120, 46, 32, 73, 116, 32, 112, 111, 115, 105, 116, 115, 32, 116, 104, 97, 116, 32, 116, 104, 101, 32, 98, 114, 97, 105, 110, 32, 109, 97, 107, 101, 115, 32, 117, 115, 101, 32, 111, 102, 32, 103, 101, 110, 101, 114, 97, 116, 105, 118, 101, 32, 109, 111, 100, 101, 108, 32, 105, 110, 32, 111, 114, 100, 101, 114, 32, 116, 111, 32, 115, 111, 108, 118, 101, 32, 116, 104, 101, 32, 105, 110, 118, 101, 114, 115, 101, 32, 112, 114, 111, 98, 108, 101, 109, 32, 111, 102, 32, 112, 101, 114, 99, 101, 112, 116, 105, 111, 110, 44, 32, 116, 104, 97, 116, 32, 105, 115, 44, 32, 105, 110, 102, 101, 114, 114, 105, 110, 103, 32, 116, 104, 101, 32, 99, 97, 117, 115, 101, 115, 32, 111, 102, 32, 115, 101, 110, 115, 111, 114, 121, 32, 111, 98, 115, 101, 114, 118, 97, 116, 105, 111, 110, 115]\n",
      "length: 222\n",
      "max value: 121\n"
     ]
    }
   ],
   "source": [
    "text = \"Predictive Processing is a process theory for the neocortex. It posits that the brain makes \" \\\n",
    "        \"use of generative model in order to solve the inverse problem of perception, that is, inferring \" \\\n",
    "        \"the causes of sensory observations\"\n",
    "\n",
    "tokens = text.encode(\"utf-8\") # convert text to bytes\n",
    "tokens = list(map(int, tokens)) # convert bytes to integers\n",
    "print(text)\n",
    "length = len(text)\n",
    "print(f\"length: {length}\")\n",
    "print(tokens)\n",
    "print(f\"length: {len(tokens)}\")\n",
    "max_value = max(tokens)\n",
    "print(f\"max value: {max_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "\n",
    "stats = get_stats(tokens)\n",
    "\n",
    "top_pair = max(stats, key=stats.get)\n",
    "\n",
    "def merge(ids, pair, idx):\n",
    "    new_ids = []\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i < len(ids) - 1 and (ids[i], ids[i+1]) == pair:\n",
    "            new_ids.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            new_ids.append(ids[i])\n",
    "            i += 1\n",
    "\n",
    "    return new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world, my name is Joe and I am a neuroscientist!\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 276 # the desired final vocab size\n",
    "num_merges = vocab_size - 256\n",
    "ids = list(tokens)\n",
    "\n",
    "merges = {}\n",
    "for i in range(num_merges):\n",
    "    stats = get_stats(ids)\n",
    "    top_pair = max(stats, key=stats.get)\n",
    "    idx = 256 + i\n",
    "    ids = merge(ids, top_pair, idx)\n",
    "    merges[top_pair] = idx\n",
    "\n",
    "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "for (p0, p1), idx in merges.items():\n",
    "    vocab[idx] = vocab[p0] + vocab[p1]\n",
    "\n",
    "def decode(ids):\n",
    "    tokens = b\"\".join(vocab[idx] for idx in ids)\n",
    "    text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
    "    return text\n",
    "\n",
    "def encode(text):\n",
    "    tokens = list(text.encode(\"utf-8\"))\n",
    "    for pair, idx in merges.items():\n",
    "        tokens = merge(tokens, pair, idx)\n",
    "    return tokens\n",
    "\n",
    "print(decode(encode(\"Hello world, my name is Joe and I am a neuroscientist!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ' world']\n"
     ]
    }
   ],
   "source": [
    "gpt2pat = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n",
    "print(re.findall(gpt2pat, \"Hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e \n",
      " t\n",
      "in\n",
      " th\n",
      "er\n",
      "or\n",
      "ti\n",
      "es\n",
      "ve \n",
      "ro\n",
      " p\n",
      " the \n",
      "of\n",
      "tive \n",
      "roc\n",
      "roces\n",
      "rocess\n",
      "ing\n",
      " i\n",
      " is\n"
     ]
    }
   ],
   "source": [
    "for pair, idx in merges.items():\n",
    "    print(decode([idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens length:  222\n",
      "ids length:  146\n",
      "compression ratio: 1.52X\n"
     ]
    }
   ],
   "source": [
    "print(\"tokens length: \", len(tokens))\n",
    "print(\"ids length: \", len(ids))\n",
    "print(f\"compression ratio: {len(tokens) / len(ids):.2f}X\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
