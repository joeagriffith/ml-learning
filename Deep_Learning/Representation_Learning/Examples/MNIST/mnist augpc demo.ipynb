{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms.v2.functional as F_v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from Utils.dataset import PreloadedDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from Deep_Learning.Representation_Learning.Methods.AugPC.train import train as train_augpc\n",
    "from Deep_Learning.Representation_Learning.Methods.AugPC.model import AugPC\n",
    "from Deep_Learning.Representation_Learning.Methods.LAugPC.train import train as train_laugpc\n",
    "from Deep_Learning.Representation_Learning.Methods.LAugPC.model import LAugPC\n",
    "from Deep_Learning.Representation_Learning.Methods.HAugPC.train import train as train_haugpc\n",
    "from Deep_Learning.Representation_Learning.Methods.HAugPC.model import HAugPC\n",
    "from Deep_Learning.Representation_Learning.Methods.BYOL.train import train as train_byol\n",
    "from Deep_Learning.Representation_Learning.Methods.BYOL.model import BYOL\n",
    "from Deep_Learning.Representation_Learning.Methods.SimCLR.train import train as train_simclr\n",
    "from Deep_Learning.Representation_Learning.Methods.SimCLR.model import SimCLR\n",
    "\n",
    "from Deep_Learning.Representation_Learning.Examples.MNIST.mnist_linear_1k import mnist_linear_1k_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST(root='../Datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "t_dataset = datasets.MNIST(root='../Datasets/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "VAL_RATIO = 0.2\n",
    "n_val = int(len(dataset) * VAL_RATIO)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # SigmoidTransform(),\n",
    "    # TanhTransform(),\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # SigmoidTransform(),\n",
    "    # TanhTransform()\n",
    "])\n",
    "augmentation = transforms.Compose([\n",
    "    # transforms.RandomCrop(20),\n",
    "    # transforms.Resize(28, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    transforms.RandomAffine(degrees=180, translate=(0.28, 0.28), scale=(0.75, 1.25), shear=25),\n",
    "    # transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "])\n",
    "\n",
    "train_set = PreloadedDataset.from_dataset(train_set, train_transform, device)\n",
    "val_set = PreloadedDataset.from_dataset(val_set, val_transform, device)\n",
    "test_set = PreloadedDataset.from_dataset(t_dataset, val_transform, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: tensor(1., device='cuda:0')\n",
      "Min value: tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Show example images\n",
    "fig, axes = plt.subplots(1, 10, figsize=(15,5))\n",
    "for i, ax in enumerate(axes):\n",
    "    img, label = train_set[i]\n",
    "    angle = torch.rand(1).item() * 360 - 180 if torch.rand(1).item() > 0.75 else 0\n",
    "    translate_x = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "    translate_y = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "    scale = torch.rand(1).item() * 0.5 + 0.75 if torch.rand(1).item() > 0.75 else 1.0\n",
    "    shear = torch.rand(1).item() * 50 - 25 if torch.rand(1).item() > 0.75 else 0\n",
    "    img = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "    ax.imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    ax.set_title(f\"Label: {label}\")\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# print max and min values\n",
    "print('Max value:', train_set.transformed_images.max())\n",
    "print('Min value:', train_set.transformed_images.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = AugPC\n",
    "backbone = 'alexnet'\n",
    "model_name = f'{Model.__name__}-{backbone}'\n",
    "log_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/logs/{model_name}/'\n",
    "save_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/models/{model_name}.pth'\n",
    "# log_dir = None\n",
    "# save_dir = None\n",
    "model = Model(1, 5, backbone=backbone).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "to_train = True\n",
    "if save_dir is not None:\n",
    "    try:\n",
    "        sd = torch.load(save_dir)\n",
    "        # change keys \"project\" to \"transition\"\n",
    "        for key in list(sd.keys()):\n",
    "            if 'project' in key:\n",
    "                sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "        model.load_state_dict(sd)\n",
    "        to_train = False\n",
    "        print('Model loaded successfully')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "        print('Model not found, training new model')\n",
    "if to_train:\n",
    "    writer = None\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(log_dir)\n",
    "    # train_augpc(\n",
    "    #     model,\n",
    "    #     train_set,\n",
    "    #     val_set,\n",
    "    #     num_epochs=500,\n",
    "    #     batch_size=128,\n",
    "    #     lr=3e-4,\n",
    "    #     wd=1.5e-6,\n",
    "    #     writer=writer,\n",
    "    #     save_dir=save_dir,\n",
    "    #     save_every=5,\n",
    "    #     aug_scaler='none'\n",
    "    # )\n",
    "\n",
    "    # train_laugpc(\n",
    "    #     model,\n",
    "    #     train_set,\n",
    "    #     val_set,\n",
    "    #     num_epochs=500,\n",
    "    #     batch_size=256,\n",
    "    #     lr=0.0001,\n",
    "    #     wd=1.5e-6,\n",
    "    #     beta=0.05,\n",
    "    #     tau_0=0.925,\n",
    "    #     tau_e=0.95,\n",
    "    #     tau_T=100,\n",
    "    #     aug_scaler='none',\n",
    "    #     learn_on_ss=False,\n",
    "    #     writer=writer,\n",
    "    #     save_dir=save_dir,\n",
    "    #     save_every=5,\n",
    "    # )\n",
    "\n",
    "    train_haugpc(\n",
    "        model,\n",
    "        train_set,\n",
    "        val_set,\n",
    "        num_epochs=500,\n",
    "        batch_size=256,\n",
    "        lr=0.000001,\n",
    "        wd=1.5e-6,\n",
    "        aug_scaler='none',\n",
    "        learn_on_ss=False,\n",
    "        normalise=False,\n",
    "        writer=writer,\n",
    "        save_dir=save_dir,\n",
    "        save_every=5,\n",
    "    )\n",
    "\n",
    "\n",
    "    # train_byol(\n",
    "    #     model,\n",
    "    #     train_set,\n",
    "    #     val_set,\n",
    "    #     num_epochs=500,\n",
    "    #     batch_size=256,\n",
    "    #     lr=0.001,\n",
    "    #     wd=1.5e-6,\n",
    "    #     augmentation=augmentation,\n",
    "    #     beta=None,\n",
    "    #     tau_0=0.996,\n",
    "    #     tau_e=0.999,\n",
    "    #     tau_T=100,\n",
    "    #     normalise=True,\n",
    "    #     learn_on_ss=False,\n",
    "    #     writer=writer,\n",
    "    #     save_dir=save_dir,\n",
    "    #     save_every=5,\n",
    "    # )\n",
    "\n",
    "    # train_simclr(\n",
    "    #     model,\n",
    "    #     train_set,\n",
    "    #     val_set,\n",
    "    #     num_epochs=500,\n",
    "    #     batch_size=256,\n",
    "    #     lr=3e-4,\n",
    "    #     wd=0.0,\n",
    "    #     temperature=1.0,\n",
    "    #     augmentation=augmentation,\n",
    "    #     writer=writer,\n",
    "    #     save_dir=save_dir,\n",
    "    #     save_every=5,\n",
    "    # )\n",
    "\n",
    "    print(f'Finished training')\n",
    "    if save_dir is not None:\n",
    "        print('Run cell again to load best (val_acc) model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 0.7276999354362488\n"
     ]
    }
   ],
   "source": [
    "# collect 100 of each target index from train_set.targets\n",
    "writer = SummaryWriter(log_dir)\n",
    "mnist_linear_1k_eval(model, writer, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eca521d7b8542f28062975f463af0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='angle', max=180, min=-180), IntSlider(value=0, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.compare(model, img, angle, translate_x, translate_y, scale, shear)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = train_set[4][0].unsqueeze(0)\n",
    "model.eval()\n",
    "\n",
    "def compare(model, img, angle, translate_x, translate_y, scale, shear):\n",
    "    img_aug = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "    action = torch.tensor([angle/180, translate_x/8, translate_y/8, (scale-1.0)/0.25, shear/25], dtype=torch.float32, device=img.device).unsqueeze(0).repeat(img.shape[0], 1)\n",
    "    img_pred = model.predict(img, action)\n",
    "    loss = F.mse_loss(img_aug, img_pred)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
    "    axes[0].imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(img_aug.squeeze().cpu(), cmap='gray')\n",
    "    axes[1].set_title('Augmented')\n",
    "    axes[1].axis('off')\n",
    "    axes[2].imshow(img_pred.squeeze().cpu().detach(), cmap='gray')\n",
    "    axes[2].set_title('Predicted')\n",
    "    axes[2].axis('off')\n",
    "    plt.show()\n",
    "    return loss.item()\n",
    "\n",
    "interact(compare, model=fixed(model), img=fixed(img), angle=(-180, 180), translate_x=(-8, 8), translate_y=(-8, 8), scale=(0.75, 1.25), shear=(-25, 25))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
