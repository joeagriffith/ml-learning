{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof that reducing r^2 gives a hebbian learning rule. also, Es are reduced when weights are random. For Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "U1 = nn.Linear(1,1, bias=False)\n",
    "# U2 = nn.Linear(1,1, bias=False)\n",
    "\n",
    "# def step(x, e1, r1, e2, r2):\n",
    "def step(x, e1, r1):\n",
    "    with torch.no_grad():\n",
    "        e1 = x - torch.matmul(U1.weight.T, r1)\n",
    "        # e2 = r1 - torch.matmul(U2.weight.T, r2)\n",
    "    r1 = r1 + U1(e1) \n",
    "    # r2 = r2 + U2(e2)\n",
    "    # return e1, r1, e2, r2\n",
    "    return e1, r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0.8994])\n",
      "e1: tensor([0.4245])\n",
      "r1: tensor([0.5636])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1)\n",
    "e1 = torch.rand(1)\n",
    "r1 = torch.rand(1)\n",
    "# e2 = torch.rand(1)\n",
    "# r2 = torch.rand(1)\n",
    "\n",
    "# print all\n",
    "print(f\"x: {x}\")\n",
    "print(f\"e1: {e1}\")\n",
    "print(f\"r1: {r1}\")\n",
    "# print(f\"e2: {e2}\")\n",
    "# print(f\"r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: tensor([0.8994])\n",
      "e1: tensor([0.0204])\n",
      "r1: tensor([1.6528], grad_fn=<AddBackward0>)\n",
      "Ur1: tensor([0.8848], grad_fn=<MvBackward0>)\n"
     ]
    }
   ],
   "source": [
    "e1 = e1.detach()\n",
    "r1 = r1.detach()\n",
    "# e2 = e2.detach()\n",
    "# r2 = r2.detach()\n",
    "# e1, r1, e2, r2 = step(x, e1, r1, e2, r2)\n",
    "e1, r1 = step(x, e1, r1)\n",
    "print(f\" x: {x}\")\n",
    "print(f\"e1: {e1}\")\n",
    "print(f\"r1: {r1}\")\n",
    "print(f\"Ur1: {torch.matmul(U1.weight.T, r1)}\")\n",
    "# print(f\"e2: {e2}\")\n",
    "# print(f\"r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U1.weight.grad:\n",
      "tensor([[0.0049]])\n",
      "U2.weight.grad:\n",
      "tensor([[0.0075]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    U1.weight.grad = torch.zeros_like(U1.weight)\n",
    "    U2.weight.grad = torch.zeros_like(U2.weight)\n",
    "loss = 0.5*((r1**2).sum() + (r2**2).sum())\n",
    "loss.sum().backward()\n",
    "print(f'U1.weight.grad:\\n{U1.weight.grad}')\n",
    "print(f'U2.weight.grad:\\n{U2.weight.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\n",
      "tensor([[0.0049]], grad_fn=<PermuteBackward0>)\n",
      "2:\n",
      "tensor([[0.0075]], grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'1:\\n{torch.matmul(e1.unsqueeze(1), r1.unsqueeze(1).T).T}')\n",
    "print(f'2:\\n{torch.matmul(e2.unsqueeze(1), r2.unsqueeze(1).T).T}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expansion to Vector Es and Rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "U1 = nn.Linear(2,4, bias=False)\n",
    "U2 = nn.Linear(4,6, bias=False)\n",
    "\n",
    "# def step(x, e1, r1, e2, r2):\n",
    "#     with torch.no_grad():\n",
    "#         e1 = x - torch.matmul(U1.weight.T, r1)\n",
    "#     r1 = r1 + U1(e1) \n",
    "#     with torch.no_grad():\n",
    "#         # r1 -= (0.01*e2)\n",
    "#         e2 = r1 - torch.matmul(U2.weight.T, r2)\n",
    "#     r2 = r2 + U2(e2)\n",
    "#     return e1, r1, e2, r2\n",
    "def step(x, e1, r1, e2, r2):\n",
    "    with torch.no_grad():\n",
    "        e1 = x - torch.matmul(U1.weight.T, r1)\n",
    "        e2 = r1 - torch.matmul(U2.weight.T, r2)\n",
    "    r1 = r1 + U1(e1) \n",
    "    r2 = r2 + U2(e2)\n",
    "    return e1, r1, e2, r2\n",
    "\n",
    "# def step(x, e1, r1, e2, r2):\n",
    "#     with torch.no_grad():\n",
    "#         e1 = torch.matmul(U1.weight.T, r1) - x\n",
    "#     r1 = r1 - U1(e1) \n",
    "#     with torch.no_grad():\n",
    "#         e2 = torch.matmul(U2.weight.T, r2) - r1\n",
    "#     r2 = r2 - U2(e2)\n",
    "#     return e1, r1, e2, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0.8860, 0.5832])\n",
      "e1: tensor([0.3376, 0.8090])\n",
      "r1: tensor([0.5779, 0.9040, 0.5547, 0.3423])\n",
      "e2: tensor([0.6343, 0.3644, 0.7104, 0.9464])\n",
      "r2: tensor([0.7890, 0.2814, 0.7886, 0.5895, 0.7539, 0.1952])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2)\n",
    "e1 = torch.rand(2)\n",
    "r1 = torch.rand(4)\n",
    "e2 = torch.rand(4)\n",
    "r2 = torch.rand(6)\n",
    "\n",
    "# print all\n",
    "print(f\"x: {x}\")\n",
    "print(f\"e1: {e1}\")\n",
    "print(f\"r1: {r1}\")\n",
    "print(f\"e2: {e2}\")\n",
    "print(f\"r2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: tensor([0.8860, 0.5832])\n",
      "e1: tensor([ 0.0021, -0.0002])\n",
      "r1: tensor([ 1.2948,  0.1165,  0.1364, -0.6544], grad_fn=<AddBackward0>)\n",
      "e2: tensor([ 0.1123,  0.0203, -0.1476, -0.1888])\n",
      "r2: tensor([ 0.0125,  1.4115,  1.3945, -1.2080,  0.3884,  0.1340],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "e1 = e1.detach()\n",
    "r1 = r1.detach()\n",
    "e2 = e2.detach()\n",
    "r2 = r2.detach()\n",
    "e1, r1, e2, r2 = step(x, e1, r1, e2, r2)\n",
    "print(f\" x: {x}\")\n",
    "print(f\"e1: {e1}\")\n",
    "print(f\"r1: {r1}\")\n",
    "print(f\"e2: {e2}\")\n",
    "print(f\"r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U1.weight.grad:\n",
      "tensor([[ 0.6933, -0.4221],\n",
      "        [ 0.3558, -0.2166],\n",
      "        [ 0.3064, -0.1865],\n",
      "        [-0.1959,  0.1192]])\n",
      "U2.weight.grad:\n",
      "tensor([[ 0.3013,  0.6518,  0.1750, -0.1821],\n",
      "        [ 0.2382,  0.5154,  0.1384, -0.1440],\n",
      "        [ 0.3859,  0.8350,  0.2242, -0.2333],\n",
      "        [ 0.1283,  0.2775,  0.0745, -0.0776],\n",
      "        [ 0.1763,  0.3815,  0.1024, -0.1066],\n",
      "        [-0.0057, -0.0124, -0.0033,  0.0035]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    U1.weight.grad = torch.zeros_like(U1.weight)\n",
    "    U2.weight.grad = torch.zeros_like(U2.weight)\n",
    "loss = 0.5*((r1**2).sum() + (r2**2).sum())\n",
    "loss.sum().backward()\n",
    "print(f'U1.weight.grad:\\n{U1.weight.grad}')\n",
    "print(f'U2.weight.grad:\\n{U2.weight.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\n",
      "tensor([[-0.6933,  0.4221],\n",
      "        [-0.3558,  0.2166],\n",
      "        [-0.3064,  0.1865],\n",
      "        [ 0.1959, -0.1192]], grad_fn=<PermuteBackward0>)\n",
      "2:\n",
      "tensor([[-0.3013, -0.6518, -0.1750,  0.1821],\n",
      "        [-0.2382, -0.5154, -0.1384,  0.1440],\n",
      "        [-0.3859, -0.8350, -0.2242,  0.2333],\n",
      "        [-0.1283, -0.2775, -0.0745,  0.0776],\n",
      "        [-0.1763, -0.3815, -0.1024,  0.1066],\n",
      "        [ 0.0057,  0.0124,  0.0033, -0.0035]], grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'1:\\n{torch.matmul(e1.unsqueeze(1), r1.unsqueeze(1).T).T}')\n",
    "print(f'2:\\n{torch.matmul(e2.unsqueeze(1), r2.unsqueeze(1).T).T}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = nn.Conv2d(1, 3, (3,3), bias=False)\n",
    "optimiser = torch.optim.SGD(U.parameters(), lr=0.001)\n",
    "Ut = nn.ConvTranspose2d(3, 1, (3,3))\n",
    "with torch.no_grad():\n",
    "    Ut.weight = U.weight\n",
    "grad = torch.zeros_like(U.weight)\n",
    "def step(x, e, r):\n",
    "    with torch.no_grad():\n",
    "        e = x - Ut(r)\n",
    "    r = r + U(e)\n",
    "    return e, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1,1,4,4))\n",
    "e = torch.zeros_like(x)\n",
    "r = torch.zeros((1,3,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.5686, -0.0906,  0.0353,  0.2347],\n",
      "          [ 0.3378,  0.1243, -0.1070, -0.0324],\n",
      "          [ 0.2056,  0.1212, -0.0081, -0.0222],\n",
      "          [ 0.0375,  0.0403,  0.0899,  0.0199]]]])\n",
      "tensor([[[[ 0.3041,  0.3235],\n",
      "          [-0.1773, -0.0444]],\n",
      "\n",
      "         [[-0.0907, -1.0017],\n",
      "          [ 0.0183, -0.6439]],\n",
      "\n",
      "         [[ 0.6487,  1.1892],\n",
      "          [-0.4736, -0.6325]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "e = e.detach()\n",
    "r = r.detach()\n",
    "e, r = step(x, e, r)\n",
    "print(e)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0582, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimiser.zero_grad()\n",
    "loss = (0.5*(r**2)).sum()\n",
    "print(loss)\n",
    "loss.backward()\n",
    "optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0782, -0.0334,  0.1071],\n",
       "          [ 0.1011, -0.0180, -0.0406],\n",
       "          [ 0.0933,  0.0231, -0.0265]]],\n",
       "\n",
       "\n",
       "        [[[-0.0347,  0.0440, -0.2194],\n",
       "          [-0.2294,  0.1033,  0.0563],\n",
       "          [-0.1653, -0.0601,  0.0118]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0226, -0.0079,  0.3732],\n",
       "          [ 0.1929, -0.0989, -0.0901],\n",
       "          [ 0.2343, -0.0069, -0.0868]]]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.weight.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
