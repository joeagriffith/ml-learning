{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approx: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "in_size = 2\n",
    "out_size = 3\n",
    "layer = nn.Linear(in_size, out_size, bias=False)\n",
    "x = torch.randn(10, in_size)\n",
    "x.requires_grad = True\n",
    "target = torch.randn(1) * 0.1\n",
    "\n",
    "parameters = [layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive\n",
    "x_norm = F.normalize(x, dim=1)\n",
    "y = layer(x_norm)\n",
    "out = F.relu(y)\n",
    "out_square = out.square()\n",
    "out_mean = out_square.mean()\n",
    "out_norm = out_mean - target\n",
    "loss = torch.log(1 + torch.exp(out_norm))\n",
    "\n",
    "vals = [x_norm, y, out, out_square, out_mean, out_norm, loss]\n",
    "for p in parameters:\n",
    "    p.zero_grad()\n",
    "for v in vals:\n",
    "    v.retain_grad()\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_norm        | exact: True  | approx: True  | maxdiff: 0.0\n",
      "out_mean        | exact: True  | approx: True  | maxdiff: 0.0\n",
      "out_square      | exact: True  | approx: True  | maxdiff: 0.0\n",
      "out             | exact: True  | approx: True  | maxdiff: 0.0\n",
      "y               | exact: True  | approx: True  | maxdiff: 0.0\n",
      "weight          | exact: False | approx: True  | maxdiff: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "dout_norm = F.sigmoid(out_norm)\n",
    "dout_mean = dout_norm\n",
    "dout_square = dout_mean  / out_square.numel()\n",
    "dout = dout_square * 2 * out\n",
    "dy = dout * y.sign()\n",
    "\n",
    "dweight = (out * out.sign() * F.sigmoid(out.square().mean() - target)).t() @ x_norm * 2/out.numel()\n",
    "\n",
    "cmp('out_norm', dout_norm, out_norm)\n",
    "cmp('out_mean', dout_mean, out_mean)\n",
    "cmp('out_square', dout_square, out_square)\n",
    "cmp('out', dout, out)\n",
    "cmp('y', dy, y)\n",
    "cmp('weight', dweight, layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative\n",
    "x_norm = F.normalize(x, dim=1)\n",
    "y = layer(x_norm)\n",
    "out = F.relu(y)\n",
    "out_square = out.square()\n",
    "out_mean = out_square.mean()\n",
    "out_norm = target - out_mean\n",
    "loss = torch.log(1 + torch.exp(out_norm))\n",
    "\n",
    "vals = [x_norm, y, out, out_square, out_mean, out_norm, loss]\n",
    "for p in parameters:\n",
    "    p.zero_grad()\n",
    "for v in vals:\n",
    "    v.retain_grad()\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_norm        | exact: True  | approx: True  | maxdiff: 0.0\n",
      "out_mean        | exact: True  | approx: True  | maxdiff: 0.0\n",
      "out_square      | exact: True  | approx: True  | maxdiff: 0.0\n",
      "out             | exact: True  | approx: True  | maxdiff: 0.0\n",
      "y               | exact: True  | approx: True  | maxdiff: 0.0\n",
      "weight          | exact: False | approx: True  | maxdiff: 1.1175870895385742e-08\n"
     ]
    }
   ],
   "source": [
    "dout_norm = F.sigmoid(out_norm)\n",
    "dout_mean = -dout_norm\n",
    "dout_square = dout_mean  / out_square.numel()\n",
    "dout = dout_square * 2 * out\n",
    "dy = dout * y.sign()\n",
    "dweight = dy.t() @ x_norm\n",
    "dweight = (out * -F.sigmoid(target-out.square().mean())).t() @ x_norm * 2/out.numel()\n",
    "# dweight = (out * out.sign() * F.sigmoid(out.square().mean() - target)).t() @ x_norm * 2/out.numel()\n",
    "\n",
    "cmp('out_norm', dout_norm, out_norm)\n",
    "cmp('out_mean', dout_mean, out_mean)\n",
    "cmp('out_square', dout_square, out_square)\n",
    "cmp('out', dout, out)\n",
    "cmp('y', dy, y)\n",
    "cmp('weight', dweight, layer.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
