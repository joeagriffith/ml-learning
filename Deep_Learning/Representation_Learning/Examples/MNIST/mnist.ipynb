{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms.v2.functional as F_v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from Utils.dataset import PreloadedDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from Deep_Learning.Representation_Learning.Methods.AugPC.train import train as train_augpc\n",
    "from Deep_Learning.Representation_Learning.Methods.AugPC.model import AugPC\n",
    "from Deep_Learning.Representation_Learning.Methods.LAugPC.train import train as train_laugpc\n",
    "from Deep_Learning.Representation_Learning.Methods.LAugPC.model import LAugPC\n",
    "from Deep_Learning.Representation_Learning.Methods.HAugPC.train import train as train_haugpc\n",
    "from Deep_Learning.Representation_Learning.Methods.HAugPC.model import HAugPC\n",
    "from Deep_Learning.Representation_Learning.Methods.BYOL.train import train as train_byol\n",
    "from Deep_Learning.Representation_Learning.Methods.BYOL.model import BYOL\n",
    "from Deep_Learning.Representation_Learning.Methods.SimCLR.train import train as train_simclr\n",
    "from Deep_Learning.Representation_Learning.Methods.SimCLR.model import SimCLR\n",
    "from Deep_Learning.Representation_Learning.Methods.SimSiam.train import train as train_simsiam\n",
    "from Deep_Learning.Representation_Learning.Methods.SimSiam.model import SimSiam\n",
    "from Deep_Learning.Representation_Learning.Methods.LAugPC2.train import train as train_laugpc2\n",
    "from Deep_Learning.Representation_Learning.Methods.LAugPC2.model import LAugPC2\n",
    "\n",
    "from Deep_Learning.Representation_Learning.Examples.MNIST.mnist_linear_1k import mnist_linear_1k_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST(root='../Datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "t_dataset = datasets.MNIST(root='../Datasets/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "VAL_RATIO = 0.2\n",
    "n_val = int(len(dataset) * VAL_RATIO)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # SigmoidTransform(),\n",
    "    # TanhTransform(),\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # SigmoidTransform(),\n",
    "    # TanhTransform()\n",
    "])\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomCrop(20),\n",
    "    # transforms.Resize(28, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    # transforms.RandomAffine(degrees=180, translate=(0.28, 0.28), scale=(0.75, 1.25), shear=25),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.75, 1.25), shear=25),\n",
    "    # transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "])\n",
    "\n",
    "train_set = PreloadedDataset.from_dataset(train_set, train_transform, device)\n",
    "val_set = PreloadedDataset.from_dataset(val_set, val_transform, device)\n",
    "test_set = PreloadedDataset.from_dataset(t_dataset, val_transform, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: tensor(1., device='cuda:0')\n",
      "Min value: tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Show example images\n",
    "fig, axes = plt.subplots(1, 10, figsize=(15,5))\n",
    "for i, ax in enumerate(axes):\n",
    "    img, label = train_set[i]\n",
    "    angle = torch.rand(1).item() * 360 - 180 if torch.rand(1).item() > 0.75 else 0\n",
    "    translate_x = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "    translate_y = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "    scale = torch.rand(1).item() * 0.5 + 0.75 if torch.rand(1).item() > 0.75 else 1.0\n",
    "    shear = torch.rand(1).item() * 50 - 25 if torch.rand(1).item() > 0.75 else 0\n",
    "    img = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "    ax.imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    ax.set_title(f\"Label: {label}\")\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# print max and min values\n",
    "print('Max value:', train_set.transformed_images.max())\n",
    "print('Min value:', train_set.transformed_images.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = AugPC\n",
    "backbone = 'alexnet'\n",
    "model_name = f'{Model.__name__}-{backbone}-AugBefore'\n",
    "log_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/logs/{model_name}/'\n",
    "save_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/models/{model_name}.pth'\n",
    "# log_dir = None\n",
    "# save_dir = None\n",
    "model = Model(1, 5, backbone=backbone).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found, training new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n",
      "Run cell again to load best (val_acc) model.\n"
     ]
    }
   ],
   "source": [
    "to_train = True\n",
    "if save_dir is not None:\n",
    "    try:\n",
    "        sd = torch.load(save_dir)\n",
    "        # change keys \"project\" to \"transition\"\n",
    "        for key in list(sd.keys()):\n",
    "            if 'project' in key:\n",
    "                sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "        model.load_state_dict(sd)\n",
    "        to_train = False\n",
    "        print('Model loaded successfully')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "        print('Model not found, training new model')\n",
    "if to_train:\n",
    "    writer = None\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(log_dir)\n",
    "\n",
    "    train_augpc(\n",
    "        model,\n",
    "        train_set,\n",
    "        val_set,\n",
    "        num_epochs=500,\n",
    "        batch_size=128,\n",
    "        lr=3e-4,\n",
    "        wd=1.5e-6,\n",
    "        writer=writer,\n",
    "        save_dir=save_dir,\n",
    "        save_every=5,\n",
    "        aug_scaler='none'\n",
    "    )\n",
    "\n",
    "    # train_laugpc(\n",
    "    #     model,\n",
    "    #     train_set,\n",
    "    #     val_set,\n",
    "    #     num_epochs=500,\n",
    "    #     batch_size=256,\n",
    "    #     lr=0.0001,\n",
    "    #     wd=1.5e-6,\n",
    "    #     beta=0.05,\n",
    "    #     tau_0=0.925,\n",
    "    #     tau_e=0.95,\n",
    "    #     tau_T=100,\n",
    "    #     aug_scaler='none',\n",
    "    #     learn_on_ss=False,\n",
    "    #     writer=writer,\n",
    "    #     save_dir=save_dir,\n",
    "    #     save_every=5,\n",
    "    # )\n",
    "\n",
    "    # train_laugpc2(\n",
    "    #     model,\n",
    "    #     train_set,\n",
    "    #     val_set,\n",
    "    #     num_epochs=500,\n",
    "    #     batch_size=256,\n",
    "    #     lr=0.0001,\n",
    "    #     wd=1.5e-6,\n",
    "    #     beta=None,\n",
    "    #     aug_scaler='none',\n",
    "    #     learn_on_ss=False,\n",
    "    #     writer=writer,\n",
    "    #     save_dir=save_dir,\n",
    "    #     save_every=5,\n",
    "    # )\n",
    "\n",
    "    # train_haugpc(\n",
    "    #     model,\n",
    "    #     train_set,\n",
    "    #     val_set,\n",
    "    #     num_epochs=500,\n",
    "    #     batch_size=256,\n",
    "    #     lr=0.0001,\n",
    "    #     wd=1.5e-6,\n",
    "    #     aug_scaler='none',\n",
    "    #     learn_on_ss=False,\n",
    "    #     normalise=False,\n",
    "    #     writer=writer,\n",
    "    #     save_dir=save_dir,\n",
    "    #     save_every=5,\n",
    "    # )\n",
    "\n",
    "    # train_byol(\n",
    "    #     model,\n",
    "    #     train_set,\n",
    "    #     val_set,\n",
    "    #     num_epochs=500,\n",
    "    #     batch_size=256,\n",
    "    #     lr=0.001,\n",
    "    #     wd=1.5e-6,\n",
    "    #     augmentation=augmentation,\n",
    "    #     beta=None,\n",
    "    #     tau_0=0.996,\n",
    "    #     tau_e=0.999,\n",
    "    #     tau_T=100,\n",
    "    #     normalise=True,\n",
    "    #     learn_on_ss=False,\n",
    "    #     writer=writer,\n",
    "    #     save_dir=save_dir,\n",
    "    #     save_every=5,\n",
    "    # )\n",
    "\n",
    "    # train_simsiam(\n",
    "    #     model,\n",
    "    #     train_set,\n",
    "    #     val_set,\n",
    "    #     num_epochs=500,\n",
    "    #     batch_size=256,\n",
    "    #     lr=0.001,\n",
    "    #     wd=0.0001,\n",
    "    #     augmentation=augmentation,\n",
    "    #     beta=None,\n",
    "    #     learn_on_ss=False,\n",
    "    #     writer=writer,\n",
    "    #     save_dir=save_dir,\n",
    "    #     save_every=5,\n",
    "    # )\n",
    "\n",
    "    # train_simclr(\n",
    "    #     model,\n",
    "    #     train_set,\n",
    "    #     val_set,\n",
    "    #     num_epochs=500,\n",
    "    #     batch_size=256,\n",
    "    #     lr=3e-4,\n",
    "    #     wd=0.0,\n",
    "    #     temperature=1.0,\n",
    "    #     augmentation=augmentation,\n",
    "    #     writer=writer,\n",
    "    #     save_dir=save_dir,\n",
    "    #     save_every=5,\n",
    "    # )\n",
    "\n",
    "    print(f'Finished training')\n",
    "    if save_dir is not None:\n",
    "        print('Run cell again to load best (val_acc) model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 0.9801999926567078\n"
     ]
    }
   ],
   "source": [
    "# collect 100 of each target index from train_set.targets\n",
    "writer = SummaryWriter(log_dir)\n",
    "mnist_linear_1k_eval(model, writer, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b570ca3c624f7bbec476d377856f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='angle', max=180, min=-180), IntSlider(value=0, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.compare(model, img, angle, translate_x, translate_y, scale, shear)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = train_set[4][0].unsqueeze(0)\n",
    "model.eval()\n",
    "\n",
    "def compare(model, img, angle, translate_x, translate_y, scale, shear):\n",
    "    img_aug = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "    action = torch.tensor([angle/180, translate_x/8, translate_y/8, (scale-1.0)/0.25, shear/25], dtype=torch.float32, device=img.device).unsqueeze(0).repeat(img.shape[0], 1)\n",
    "    # img_pred = model.predict(img, action)\n",
    "    img_pred = model.predict(img.flatten(1), action).view(img.shape)\n",
    "    loss = F.mse_loss(img_aug, img_pred)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
    "    axes[0].imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(img_aug.squeeze().cpu(), cmap='gray')\n",
    "    axes[1].set_title('Augmented')\n",
    "    axes[1].axis('off')\n",
    "    axes[2].imshow(img_pred.squeeze().cpu().detach(), cmap='gray')\n",
    "    axes[2].set_title('Predicted')\n",
    "    axes[2].axis('off')\n",
    "    plt.show()\n",
    "    return loss.item()\n",
    "\n",
    "interact(compare, model=fixed(model), img=fixed(img), angle=(-180, 180), translate_x=(-8, 8), translate_y=(-8, 8), scale=(0.75, 1.25), shear=(-25, 25))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
