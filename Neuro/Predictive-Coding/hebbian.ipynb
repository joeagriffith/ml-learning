{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof that reducing r^2 gives a hebbian learning rule. also, Es are reduced when weights are random. For Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [],
   "source": [
    "U1 = nn.Linear(1,1, bias=True)\n",
    "# U2 = nn.Linear(1,1, bias=False)\n",
    "\n",
    "# def step(x, e1, r1, e2, r2):\n",
    "def step(x, e1, r1):\n",
    "    with torch.no_grad():\n",
    "        e1 = x - torch.matmul(U1.weight.T, r1)\n",
    "        if U1.bias is not None:\n",
    "            e1 = e1 + U1.bias\n",
    "        # e2 = r1 - torch.matmul(U2.weight.T, r2)\n",
    "    r1 = r1 + U1(e1) \n",
    "    # r2 = r2 + U2(e2)\n",
    "    # return e1, r1, e2, r2\n",
    "    return e1, r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0.3278])\n",
      "e1: tensor([0.6532])\n",
      "r1: tensor([0.3958])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1)\n",
    "e1 = torch.rand(1)\n",
    "r1 = torch.rand(1)\n",
    "# e2 = torch.rand(1)\n",
    "# r2 = torch.rand(1)\n",
    "\n",
    "# print all\n",
    "print(f\"x: {x}\")\n",
    "print(f\"e1: {e1}\")\n",
    "print(f\"r1: {r1}\")\n",
    "# print(f\"e2: {e2}\")\n",
    "# print(f\"r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: tensor([0.3278])\n",
      "e1: tensor([0.9079])\n",
      "r1: tensor([-1.6491], grad_fn=<AddBackward0>)\n",
      "Ur1: tensor([-1.2906], grad_fn=<MvBackward0>)\n"
     ]
    }
   ],
   "source": [
    "e1 = e1.detach()\n",
    "r1 = r1.detach()\n",
    "# e2 = e2.detach()\n",
    "# r2 = r2.detach()\n",
    "# e1, r1, e2, r2 = step(x, e1, r1, e2, r2)\n",
    "e1, r1 = step(x, e1, r1)\n",
    "print(f\" x: {x}\")\n",
    "print(f\"e1: {e1}\")\n",
    "print(f\"r1: {r1}\")\n",
    "print(f\"Ur1: {torch.matmul(U1.weight.T, r1)}\")\n",
    "# print(f\"e2: {e2}\")\n",
    "# print(f\"r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U1.weight.grad:\n",
      "tensor([[0.0049]])\n",
      "U2.weight.grad:\n",
      "tensor([[0.0075]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    U1.weight.grad = torch.zeros_like(U1.weight)\n",
    "    U2.weight.grad = torch.zeros_like(U2.weight)\n",
    "loss = 0.5*((r1**2).sum() + (r2**2).sum())\n",
    "loss.sum().backward()\n",
    "print(f'U1.weight.grad:\\n{U1.weight.grad}')\n",
    "print(f'U2.weight.grad:\\n{U2.weight.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\n",
      "tensor([[0.0049]], grad_fn=<PermuteBackward0>)\n",
      "2:\n",
      "tensor([[0.0075]], grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'1:\\n{torch.matmul(e1.unsqueeze(1), r1.unsqueeze(1).T).T}')\n",
    "print(f'2:\\n{torch.matmul(e2.unsqueeze(1), r2.unsqueeze(1).T).T}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expansion to Vector Es and Rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5406,  0.5869],\n",
      "        [-0.1657,  0.6496],\n",
      "        [-0.1549,  0.1427],\n",
      "        [-0.3443,  0.4153]], requires_grad=True)\n",
      "tensor(1.0666)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4408, -0.3668,  0.4346,  0.0936],\n",
      "        [ 0.3694,  0.0677,  0.2411, -0.0706],\n",
      "        [ 0.3854,  0.0739, -0.2334,  0.1274],\n",
      "        [-0.2304, -0.0586, -0.2031,  0.3317],\n",
      "        [-0.3947, -0.2305, -0.1412, -0.3006],\n",
      "        [ 0.0472, -0.4938,  0.4516, -0.4247]], requires_grad=True)\n",
      "tensor(1.3466)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "U1 = nn.Linear(2,4, bias=False)\n",
    "# U1.weight.data = torch.ones_like(U1.weight.data)\n",
    "# U1.weight.data /= U1.weight.data.norm()\n",
    "U2 = nn.Linear(4,6, bias=False)\n",
    "# U2.weight.data = torch.ones_like(U2.weight.data) / 24.0\n",
    "# U2.weight.data /= U2.weight.data.norm()\n",
    "\n",
    "print(U1.weight)\n",
    "u1mag = (U1.weight.data @ U1.weight.data.T).norm()\n",
    "print(u1mag)\n",
    "print(U2.weight)\n",
    "u2mag = (U2.weight.data @ U2.weight.data.T).norm()\n",
    "print(u2mag)\n",
    "\n",
    "# def step(x, e1, r1, e2, r2):\n",
    "#     with torch.no_grad():\n",
    "#         e1 = x - torch.matmul(U1.weight.T, r1)\n",
    "#     r1 = r1 + U1(e1) \n",
    "#     with torch.no_grad():\n",
    "#         # r1 -= (0.01*e2)\n",
    "#         e2 = r1 - torch.matmul(U2.weight.T, r2)\n",
    "#     r2 = r2 + U2(e2)\n",
    "#     return e1, r1, e2, r2\n",
    "def step(x, e1, r1, e2, r2):\n",
    "    with torch.no_grad():\n",
    "        e1 = x - torch.matmul(U1.weight.T, r1)\n",
    "        e2 = r1 - torch.matmul(U2.weight.T, r2)\n",
    "    r1 = r1 + U1(e1) \n",
    "    r2 = r2 + U2(e2)\n",
    "    return e1, r1, e2, r2\n",
    "\n",
    "# def step(x, e1, r1, e2, r2):\n",
    "#     with torch.no_grad():\n",
    "#         e1 = torch.matmul(U1.weight.T, r1) - x\n",
    "#     r1 = r1 - U1(e1) \n",
    "#     with torch.no_grad():\n",
    "#         e2 = torch.matmul(U2.weight.T, r2) - r1\n",
    "#     r2 = r2 - U2(e2)\n",
    "#     return e1, r1, e2, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0.8860, 0.5832])\n",
      "e1: tensor([0.3376, 0.8090])\n",
      "r1: tensor([0.5779, 0.9040, 0.5547, 0.3423])\n",
      "e2: tensor([0.6343, 0.3644, 0.7104, 0.9464])\n",
      "r2: tensor([0.7890, 0.2814, 0.7886, 0.5895, 0.7539, 0.1952])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2)\n",
    "e1 = torch.rand(2)\n",
    "r1 = torch.rand(4)\n",
    "e2 = torch.rand(4)\n",
    "r2 = torch.rand(6)\n",
    "\n",
    "# print all\n",
    "print(f\"x: {x}\")\n",
    "print(f\"e1: {e1}\")\n",
    "print(f\"r1: {r1}\")\n",
    "print(f\"e2: {e2}\")\n",
    "print(f\"r2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: tensor([0.8860, 0.5832])\n",
      "e1: tensor([ 0.0039, -0.0003])\n",
      "r1: tensor([ 1.2938,  0.1169,  0.1367, -0.6536], grad_fn=<AddBackward0>)\n",
      "e2: tensor([ 0.1275,  0.0375, -0.1608, -0.2237])\n",
      "r2: tensor([ 0.0522,  1.3909,  1.3393, -1.1483,  0.3598,  0.1252],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "e1 = e1.detach()\n",
    "r1 = r1.detach()\n",
    "e2 = e2.detach()\n",
    "r2 = r2.detach()\n",
    "e1, r1, e2, r2 = step(x, e1, r1, e2, r2)\n",
    "print(f\" x: {x}\")\n",
    "print(f\"e1: {e1}\")\n",
    "print(f\"r1: {r1}\")\n",
    "print(f\"e2: {e2}\")\n",
    "print(f\"r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U1.weight.grad:\n",
      "tensor([[ 0.0547, -0.1774],\n",
      "        [ 0.0585, -0.1900],\n",
      "        [ 0.0626, -0.2031],\n",
      "        [ 0.0142, -0.0459]])\n",
      "U2.weight.grad:\n",
      "tensor([[ 0.0462,  0.3034,  0.0326,  0.1623],\n",
      "        [ 0.1640,  1.0771,  0.1159,  0.5761],\n",
      "        [ 0.1533,  1.0070,  0.1084,  0.5386],\n",
      "        [ 0.1009,  0.6623,  0.0713,  0.3543],\n",
      "        [ 0.0279,  0.1831,  0.0197,  0.0979],\n",
      "        [-0.0146, -0.0957, -0.0103, -0.0512]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    U1.weight.grad = torch.zeros_like(U1.weight)\n",
    "    U2.weight.grad = torch.zeros_like(U2.weight)\n",
    "loss = 0.5*((r1**2).sum() + (r2**2).sum())\n",
    "loss.sum().backward()\n",
    "print(f'U1.weight.grad:\\n{U1.weight.grad}')\n",
    "print(f'U2.weight.grad:\\n{U2.weight.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\n",
      "tensor([[-0.6933,  0.4221],\n",
      "        [-0.3558,  0.2166],\n",
      "        [-0.3064,  0.1865],\n",
      "        [ 0.1959, -0.1192]], grad_fn=<PermuteBackward0>)\n",
      "2:\n",
      "tensor([[-0.3013, -0.6518, -0.1750,  0.1821],\n",
      "        [-0.2382, -0.5154, -0.1384,  0.1440],\n",
      "        [-0.3859, -0.8350, -0.2242,  0.2333],\n",
      "        [-0.1283, -0.2775, -0.0745,  0.0776],\n",
      "        [-0.1763, -0.3815, -0.1024,  0.1066],\n",
      "        [ 0.0057,  0.0124,  0.0033, -0.0035]], grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'1:\\n{torch.matmul(e1.unsqueeze(1), r1.unsqueeze(1).T).T}')\n",
    "print(f'2:\\n{torch.matmul(e2.unsqueeze(1), r2.unsqueeze(1).T).T}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = nn.Conv2d(1, 3, (3,3), bias=False)\n",
    "optimiser = torch.optim.SGD(U.parameters(), lr=0.001)\n",
    "Ut = nn.ConvTranspose2d(3, 1, (3,3))\n",
    "with torch.no_grad():\n",
    "    Ut.weight = U.weight\n",
    "grad = torch.zeros_like(U.weight)\n",
    "def step(x, e, r):\n",
    "    with torch.no_grad():\n",
    "        e = x - Ut(r)\n",
    "    r = r + U(e)\n",
    "    return e, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1,1,4,4))\n",
    "e = torch.zeros_like(x)\n",
    "r = torch.zeros((1,3,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.5686, -0.0906,  0.0353,  0.2347],\n",
      "          [ 0.3378,  0.1243, -0.1070, -0.0324],\n",
      "          [ 0.2056,  0.1212, -0.0081, -0.0222],\n",
      "          [ 0.0375,  0.0403,  0.0899,  0.0199]]]])\n",
      "tensor([[[[ 0.3041,  0.3235],\n",
      "          [-0.1773, -0.0444]],\n",
      "\n",
      "         [[-0.0907, -1.0017],\n",
      "          [ 0.0183, -0.6439]],\n",
      "\n",
      "         [[ 0.6487,  1.1892],\n",
      "          [-0.4736, -0.6325]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "e = e.detach()\n",
    "r = r.detach()\n",
    "e, r = step(x, e, r)\n",
    "print(e)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0582, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimiser.zero_grad()\n",
    "loss = (0.5*(r**2)).sum()\n",
    "print(loss)\n",
    "loss.backward()\n",
    "optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0782, -0.0334,  0.1071],\n",
       "          [ 0.1011, -0.0180, -0.0406],\n",
       "          [ 0.0933,  0.0231, -0.0265]]],\n",
       "\n",
       "\n",
       "        [[[-0.0347,  0.0440, -0.2194],\n",
       "          [-0.2294,  0.1033,  0.0563],\n",
       "          [-0.1653, -0.0601,  0.0118]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0226, -0.0079,  0.3732],\n",
       "          [ 0.1929, -0.0989, -0.0901],\n",
       "          [ 0.2343, -0.0069, -0.0868]]]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.weight.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
