{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/ai-insights-cobet/building-mamba-from-scratch-a-comprehensive-code-walkthrough-5db040c28049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x2173fedae90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "import os\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = torch.arange(0, 1, 0.00001)\n",
    "y = -x.log()\n",
    "\n",
    "plt.plot(x, y)\n",
    "# Big text\n",
    "plt.xlabel('Probability p(x)', fontsize=14)\n",
    "plt.ylabel('Surprisal -ln p(x)', fontsize=14)\n",
    "# plt.ylim(0, 10.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MAMBA = 1\n",
    "DIFFERENT_H_STATES_RECURRENT_UPDATE_MECHANISM = 0\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S6(nn.Module):\n",
    "    def __init__(self, seq_len, d_model, state_size, device):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_model, device=device)\n",
    "        self.fc2 = nn.Linear(d_model, state_size, device=device)\n",
    "        self.fc3 = nn.Linear(d_model, state_size, device=device)\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.d_model = d_model\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.A = nn.Parameter(F.normalize(torch.ones(d_model, state_size, device=device), p=2, dim=-1))\n",
    "        nn.init.xavier_uniform_(self.A)\n",
    "\n",
    "        self.B = torch.zeros(batch_size, self.seq_len, self.state_size, device=device)\n",
    "        self.C = torch.zeros(batch_size, self.seq_len, self.state_size, device=device)\n",
    "\n",
    "        self.delta = torch.zeros(batch_size, self.seq_len, self.d_model, device=device)\n",
    "        self.dA = torch.zeros(batch_size, self.seq_len, self.d_model, self.state_size, device=device)\n",
    "        self.dB = torch.zeros(batch_size, self.seq_len, self.d_model, self.state_size, device=device)\n",
    "\n",
    "        self.h = torch.zeros(batch_size, self.seq_len, self.d_model, self.state_size, device=device)\n",
    "        self.y = torch.zeros(batch_size, self.seq_len, self.d_model, device=device)\n",
    "\n",
    "    \n",
    "    def discretisation(self):\n",
    "        self.dB = torch.einsum(\"bld,bln->bldn\", self.delta, self.B)\n",
    "        self.dA = torch.exp(torch.einsum(\"bld,dn->bldn\", self.delta, self.A))\n",
    "        # return self.dA, self.dB\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.delta = F.softplus(self.fc1(x))\n",
    "        self.B = self.fc2(x)\n",
    "        self.C = self.fc3(x)\n",
    "\n",
    "\n",
    "        self.discretisation()\n",
    "\n",
    "        if DIFFERENT_H_STATES_RECURRENT_UPDATE_MECHANISM:\n",
    "\n",
    "            global current_batch_size\n",
    "            current_batch_size = x.shape[0]\n",
    "\n",
    "            if self.h.shape[0] != current_batch_size:\n",
    "                different_batch_size = True\n",
    "                h_new = torch.einsum('bldn,bldn->bldn', self.dA, self.h[:current_batch_size, ...]) + rearrange(x, \"b l d -> b l d 1\") * self.dB\n",
    "\n",
    "            else:\n",
    "                different_batch_size = False\n",
    "                h_new = torch.einsum('bldn,bldn->bldn', self.dA, self.h) + rearrange(x, \"b l d -> b l d 1\") * self.dB\n",
    "\n",
    "            self.y = torch.einsum('bln,bldn->bld', self.C, h_new)\n",
    "\n",
    "            global temp_buffer\n",
    "            temp_buffer = h_new.detach().clone() if not self.h.requires_grad else h_new.clone()\n",
    "\n",
    "            return self.y\n",
    "        \n",
    "        else:\n",
    "\n",
    "            h = torch.zeros(x.size(0), self.seq_len, self.d_model, self.state_size, device=x.device)\n",
    "            h = torch.einsum('bldn,bldn->bldn', self.dA, h) + rearrange(x, \"b l d -> b l d 1\") * self.dB\n",
    "\n",
    "            y = torch.einsum('bln,bldn->bld', self.C, h)\n",
    "\n",
    "            return y\n",
    "\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, d_model, device, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(d_model, device=device))\n",
    "\n",
    "    def forward(self, x):\n",
    "        normalised = x * torch.rsqrt(x.square().mean(-1, keepdim=True) + self.eps)\n",
    "        scaled = normalised * self.weight\n",
    "        return scaled\n",
    "\n",
    "\n",
    "class MambaBlock(nn.Module):\n",
    "    def __init__(self, seq_len, d_model, state_size, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.inp_proj = nn.Linear(d_model, 2*d_model, device=device)\n",
    "        self.out_proj = nn.Linear(2*d_model, d_model, device=device)\n",
    "        self.out_proj.bias._no_weight_decay = True\n",
    "        nn.init.constant_(self.out_proj.bias, 1.0)\n",
    "\n",
    "        self.D = nn.Linear(d_model, 2*d_model, device=device)\n",
    "\n",
    "        self.S6 = S6(seq_len, 2*d_model, state_size, device)\n",
    "\n",
    "        self.conv = nn.Conv1d(seq_len, seq_len, kernel_size=3, padding=1, device=device)\n",
    "        self.conv_linear = nn.Linear(2*d_model, 2*d_model, device=device)\n",
    "\n",
    "        self.norm = RMSNorm(d_model, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        inp = self.norm(x)\n",
    "        x = self.inp_proj(inp)\n",
    "\n",
    "        x = F.silu(self.conv(x))\n",
    "        x = self.conv_linear(x)\n",
    "\n",
    "        x_ssm = F.silu(self.S6(x))\n",
    "        x_res = F.silu(self.D(inp))\n",
    "        x = x_ssm * x_res\n",
    "\n",
    "        return self.out_proj(x)\n",
    "    \n",
    "class Mamba(nn.Module):\n",
    "    def __init__(self, seq_len, d_model, state_size, device):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            MambaBlock(seq_len, d_model, state_size, device),\n",
    "            MambaBlock(seq_len, d_model, state_size, device),\n",
    "            MambaBlock(seq_len, d_model, state_size, device),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.blocks(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 100, 8])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 8\n",
    "state_size = 128\n",
    "seq_len = 100\n",
    "batch_size = 256\n",
    "last_batch_size = 81\n",
    "current_batch_size = batch_size\n",
    "different_batch_size = False\n",
    "h_new = None\n",
    "temp_buffer = None\n",
    "\n",
    "model = Mamba(seq_len, d_model, state_size, device)\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, d_model, device=device)\n",
    "norm = RMSNorm(d_model, device=device)\n",
    "x = norm(x)\n",
    "out = model(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enwiki8Dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.data.items()}\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for padding\n",
    "def pad_sequences_3d(sequences, max_len=None, pad_value=0):\n",
    "    # Assuming sequences is a tensor of shape (batch_size, seq_len, feature_size)\n",
    "    batch_size, seq_len, feature_size = sequences.shape\n",
    "\n",
    "    if max_len is None:\n",
    "        max_len = seq_len + 1\n",
    "\n",
    "\n",
    "    # Initialize padded_sequences with the pad_value\n",
    "    padded_sequences = torch.full((batch_size, max_len, feature_size), fill_value=pad_value, dtype=sequences.dtype, device=sequences.device)\n",
    "    # Pad each sequence to the max_len\n",
    "    padded_sequences[:, :seq_len, :] = sequences\n",
    "\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, tokenizer, data_loader, optimizer, criterion, device, max_grad_norm=1.0, DEBUGGING_IS_ON=False):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_data = batch['input_ids'].clone().to(device)\n",
    "        attention_mask = batch['attention_mask'].clone().to(device)\n",
    "\n",
    "        # In most sequence modeling tasks, like language modeling, the target should be the next token\n",
    "        # in the sequence rather than the input token itself.\n",
    "        # This is because the model's goal is to predict the next word given the previous words.\n",
    "        # Shift the input data by one position to get the target, so that each target token\n",
    "        # is the next token following the input token.\n",
    "        target = input_data[:, 1:]\n",
    "        input_data = input_data[:, :-1]\n",
    "\n",
    "        # Pad all the sequences in the batch:\n",
    "        input_data = pad_sequences_3d(input_data, pad_value=tokenizer.pad_token_id)\n",
    "        target = pad_sequences_3d(target, max_len=input_data.size(1), pad_value=tokenizer.pad_token_id)\n",
    "\n",
    "        if USE_MAMBA:\n",
    "            output = model(input_data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        # Clip gradients: gradients are modified in place\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        for name, param in model.named_parameters():\n",
    "           if 'out_proj.bias' not in name:\n",
    "               # clip weights but not bias for out_proj\n",
    "               torch.nn.utils.clip_grad_norm_(param, max_norm=max_grad_norm)\n",
    "\n",
    "        if DEBUGGING_IS_ON:\n",
    "            for name, parameter in model.named_parameters():\n",
    "                if parameter.grad is not None:\n",
    "                    print(f\"{name} gradient: {parameter.grad.data.norm(2)}\")\n",
    "                else:\n",
    "                    print(f\"{name} has no gradient\")\n",
    "\n",
    "        if USE_MAMBA and DIFFERENT_H_STATES_RECURRENT_UPDATE_MECHANISM:\n",
    "            model.S6.h[:current_batch_size, ...].copy_(temp_buffer)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_data = batch['input_ids'].clone().detach().to(device)\n",
    "            attention_mask = batch['attention_mask'].clone().detach().to(device)\n",
    "\n",
    "            # In most sequence modeling tasks, like language modeling, the target should be the next token\n",
    "            # in the sequence rather than the input token itself.\n",
    "            # This is because the model's goal is to predict the next word given the previous words.\n",
    "            # Shift the input data by one position to get the target, so that each target token\n",
    "            # is the next token following the input token.\n",
    "            target = input_data[:, 1:]\n",
    "            input_data = input_data[:, :-1]\n",
    "\n",
    "            # Pad all the sequences in the batch:\n",
    "            input_data = pad_sequences_3d(input_data, pad_value=tokenizer.pad_token_id)\n",
    "            target = pad_sequences_3d(target, max_len=input_data.size(1), pad_value=tokenizer.pad_token_id)\n",
    "\n",
    "            if USE_MAMBA:\n",
    "                output = model(input_data)\n",
    "                loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(loss):\n",
    "    return math.exp(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_enwiki8_dataset():\n",
    "    print(f\"Download and extract enwiki8 data\")\n",
    "    url = \"http://mattmahoney.net/dc/enwik8.zip\"\n",
    "    urllib.request.urlretrieve(url, \"enwik8.zip\")\n",
    "\n",
    "    with ZipFile(\"enwik8.zip\") as f:\n",
    "        data = f.read(\"enwik8\").decode(\"utf-8\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode the dataset\n",
    "def encode_dataset(tokenizer, text_data):\n",
    "    def batch_encode(tokenizer, text_data, batch_size=1000):\n",
    "        # Tokenize in batches\n",
    "        batched_input_ids = []\n",
    "        for i in range(0, len(text_data), batch_size):\n",
    "            batch = text_data[i:i+batch_size]\n",
    "            inputs = tokenizer(batch, add_special_tokens=True, truncation=True,\n",
    "                               padding='max_length', max_length=seq_len,\n",
    "                               return_tensors='pt')\n",
    "            batched_input_ids.append(inputs['input_ids'])\n",
    "        return torch.cat(batched_input_ids)\n",
    "\n",
    "    # Assuming enwiki8_data is a list of sentences\n",
    "    input_ids = batch_encode(tokenizer, enwiki8_data)\n",
    "\n",
    "    # vocab_size is the number of unique tokens in the tokenizer's vocabulary\n",
    "    global vocab_size\n",
    "    vocab_size = len(tokenizer.vocab)  # Note that for some tokenizers, we might access the vocab directly\n",
    "    print(f\"vocab_size = {vocab_size}\")\n",
    "\n",
    "    # Create an embedding layer\n",
    "    # embedding_dim is the size of the embedding vectors (MAMBA model's D)\n",
    "    embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model)\n",
    "\n",
    "    # Pass `input_ids` through the embedding layer\n",
    "    # This will change `input_ids` from shape [B, L] to [B, L, D]\n",
    "    #encoded_input = embedding_layer(input_ids)   ## this eats memory, so use batched_embedding_calls instead\n",
    "    def batch_embedding_calls(input_ids, embedding_layer, batch_size=256):\n",
    "        # Check if input_ids is already a tensor, if not convert it\n",
    "        if not isinstance(input_ids, torch.Tensor):\n",
    "            input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "\n",
    "        # Calculate the number of batches needed\n",
    "        num_batches = math.ceil(input_ids.size(0) / batch_size)\n",
    "\n",
    "        # List to hold the output embeddings\n",
    "        output_embeddings = []\n",
    "\n",
    "        # Process each batch\n",
    "        for i in range(num_batches):\n",
    "            # Calculate start and end indices for the current batch\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "\n",
    "            # Get the batch\n",
    "            input_id_batch = input_ids[start_idx:end_idx]\n",
    "\n",
    "            # Call the embedding layer\n",
    "            with torch.no_grad():  # No need gradients for this operation\n",
    "                batch_embeddings = embedding_layer(input_id_batch)\n",
    "\n",
    "            # Append the result to the list\n",
    "            output_embeddings.append(batch_embeddings)\n",
    "\n",
    "        # Concatenate the embeddings from each batch into a single tensor\n",
    "        all_embeddings = torch.cat(output_embeddings, dim=0)\n",
    "\n",
    "        return all_embeddings\n",
    "\n",
    "    # `input_ids` is a list or tensor of the input IDs and `embedding_layer` is model's embedding layer\n",
    "    if USE_MAMBA:\n",
    "        # Set `batch_size` to a value that works for memory constraints\n",
    "        encoded_inputs = batch_embedding_calls(input_ids, embedding_layer, batch_size=1).float()\n",
    "\n",
    "    attention_mask = (input_ids != tokenizer.pad_token_id).type(input_ids.dtype)\n",
    "\n",
    "    return encoded_inputs, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<?, ?B/s]\n",
      "config.json: 100%|██████████| 570/570 [00:00<?, ?B/s] \n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.32MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.93MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load a pretrained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing raw data...\n",
      "Download and extract enwiki8 data\n",
      "vocab_size = 30522\n",
      "finished tokenizing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:41<16:27, 41.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 8.8437, Validation Loss: 8.6865, Validation Perplexity: 5922.4782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [01:20<15:25, 40.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 8.8296, Validation Loss: 8.5702, Validation Perplexity: 5272.3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [01:59<14:34, 39.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 7.8347, Validation Loss: 5.4794, Validation Perplexity: 239.6987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [02:39<13:52, 39.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: -5.9380, Validation Loss: -21.7479, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [03:18<13:12, 39.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: -49.6760, Validation Loss: -80.3540, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [03:58<12:31, 39.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Training Loss: -134.6293, Validation Loss: -189.7020, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [04:37<11:51, 39.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Training Loss: -278.9517, Validation Loss: -370.2170, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [05:17<11:11, 39.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Training Loss: -513.5786, Validation Loss: -663.9566, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [05:56<10:31, 39.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Training Loss: -891.1474, Validation Loss: -1134.8793, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [06:36<09:51, 39.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: -1487.8922, Validation Loss: -1878.2194, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [07:15<09:11, 39.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Training Loss: -2422.2782, Validation Loss: -3043.9231, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [07:54<08:32, 39.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Training Loss: -3879.2015, Validation Loss: -4857.3017, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [08:34<07:52, 39.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Training Loss: -6109.1288, Validation Loss: -7624.1411, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [09:13<07:12, 39.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Training Loss: -9502.0034, Validation Loss: -11820.2715, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [09:52<06:33, 39.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Training Loss: -14611.1538, Validation Loss: -18136.4497, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [10:32<05:54, 39.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Training Loss: -22251.5789, Validation Loss: -27535.1717, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [11:11<05:15, 39.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Training Loss: -33529.3880, Validation Loss: -41334.8787, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [11:50<04:35, 39.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Training Loss: -50046.2264, Validation Loss: -61496.8943, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [12:30<03:56, 39.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Training Loss: -74003.3329, Validation Loss: -90775.7302, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [13:09<03:16, 39.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Training Loss: -108687.3361, Validation Loss: -132969.1465, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [13:49<02:37, 39.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Training Loss: -158385.8005, Validation Loss: -193252.4986, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [14:28<01:58, 39.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Training Loss: -229383.6311, Validation Loss: -278797.5958, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [15:08<01:18, 39.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Training Loss: -329729.1901, Validation Loss: -399864.6446, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [15:47<00:39, 39.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Training Loss: -470856.2752, Validation Loss: -569100.1214, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [16:26<00:00, 39.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Training Loss: -667271.3972, Validation Loss: -804622.2829, Validation Perplexity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming encoded_inputs is a preprocessed tensor of shape [num_samples, seq_len, d_model]\n",
    "encoded_inputs_file = 'encoded_inputs_mamba.pt'\n",
    "\n",
    "\n",
    "if os.path.exists(encoded_inputs_file):\n",
    "    print(\"Loading pre-tokenized data...\")\n",
    "    encoded_inputs = torch.load(encoded_inputs_file)\n",
    "else:\n",
    "    print(\"Tokenizing raw data...\")\n",
    "    enwiki8_data = load_enwiki8_dataset()\n",
    "    encoded_inputs, attention_mask = encode_dataset(tokenizer, enwiki8_data)\n",
    "    torch.save(encoded_inputs, encoded_inputs_file)\n",
    "    print(f\"finished tokenizing data\")\n",
    "\n",
    "\n",
    "# Combine into a single dictionary\n",
    "data = {\n",
    "    'input_ids': encoded_inputs,\n",
    "    'attention_mask': attention_mask\n",
    "}\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "total_size = len(data['input_ids'])\n",
    "train_size = int(total_size * 0.8)\n",
    "\n",
    "train_data = {key: val[:train_size] for key, val in data.items()}\n",
    "val_data = {key: val[train_size:] for key, val in data.items()}\n",
    "\n",
    "train_dataset = Enwiki8Dataset(train_data)\n",
    "val_dataset = Enwiki8Dataset(val_data)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "\n",
    "model = Mamba(seq_len, d_model, state_size, device).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-6)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25  # Number of epochs to train for\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):  # loop over the dataset multiple times\n",
    "    train_loss = train(model, tokenizer, train_loader, optimizer, criterion, device, max_grad_norm=10.0, DEBUGGING_IS_ON=False)\n",
    "    val_loss = evaluate(model, val_loader, criterion, device)\n",
    "    val_perplexity = calculate_perplexity(val_loss)\n",
    "    print(f'Epoch: {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Perplexity: {val_perplexity:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
