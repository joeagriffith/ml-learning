{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from Utils.dataset import PreloadedDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST(root='../Datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "t_dataset = datasets.MNIST(root='../Datasets/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "VAL_RATIO = 0.2\n",
    "n_val = int(len(dataset) * VAL_RATIO)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# transform = transforms.Normalize((0.1307,), (0.3081,))\n",
    "transform = None\n",
    "\n",
    "train_set = PreloadedDataset.from_dataset(train_set, transform, device)\n",
    "val_set = PreloadedDataset.from_dataset(val_set, transform, device)\n",
    "test_set = PreloadedDataset.from_dataset(t_dataset, transform, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        model,\n",
    "        train_set,\n",
    "        val_set,\n",
    "        criterion,\n",
    "        n_epochs,\n",
    "):\n",
    "    # device = next(model.parameters()).device\n",
    "    # device=device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    train_len = 48000\n",
    "    x_train = train_set[:train_len][0]\n",
    "    z_train = torch.randn(train_len, model.z_dim).to(device)\n",
    "    z_train.requires_grad = True\n",
    "    z_train_optimiser = torch.optim.AdamW([z_train], lr=1e-1)\n",
    "\n",
    "    val_len = 12000\n",
    "    x_val = val_set[:val_len][0]\n",
    "    z_val = torch.randn(val_len, model.z_dim).to(device)\n",
    "    z_val.requires_grad = True\n",
    "    z_val_optimiser = torch.optim.AdamW([z_val], lr=1e-1)\n",
    "\n",
    "    p_optimiser = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    loop = tqdm(range(n_epochs), leave=False)\n",
    "    for epoch in loop:\n",
    "        model.train()\n",
    "\n",
    "        if epoch > 0:\n",
    "            loop.set_description(f'Epoch [{epoch}/{n_epochs}]')\n",
    "            loop.set_postfix(train_loss=train_losses[-1], val_loss=val_losses[-1])\n",
    "\n",
    "        model.step(x_train, z_train, z_train_optimiser)\n",
    "\n",
    "        x_hat = model.decoder(z_train.detach())\n",
    "        loss = criterion(x_hat, x_train)\n",
    "\n",
    "        p_optimiser.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        p_optimiser.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        model.step(x_val, z_val, z_val_optimiser)\n",
    "        x_hat = model.decoder(z_val)\n",
    "        loss = criterion(x_hat, x_val)\n",
    "        val_losses.append(loss.item())\n",
    "        if epoch % 100 == 0:\n",
    "            classifier = nn.Linear(model.z_dim, 10).to(device)\n",
    "            c_optimiser = torch.optim.AdamW(classifier.parameters(), lr=1e-3)\n",
    "            train_labels = train_set[:train_len][1]\n",
    "            val_labels = val_set[:val_len][1]\n",
    "            b_size = 250\n",
    "            for _ in range(10):\n",
    "                for i in range(0, train_len, b_size):\n",
    "                    z = z_train[i:i + b_size]\n",
    "                    y = classifier(z.detach())\n",
    "                    loss = F.cross_entropy(y, train_labels[i:i + b_size])\n",
    "                    classifier.zero_grad()\n",
    "                    c_optimiser.zero_grad(set_to_none=True)\n",
    "                    loss.backward()\n",
    "                    c_optimiser.step()\n",
    "            \n",
    "            # val accuracy\n",
    "            correct = 0\n",
    "            for i in range(0, 12000, b_size):\n",
    "                z = z_val[i:i + b_size]\n",
    "                y = classifier(z)\n",
    "                correct += (y.argmax(dim=1) == val_labels[i:i + b_size]).sum().item()\n",
    "            accuracy = correct / 12000\n",
    "            print(f'Epoch {epoch} Val accuracy: {accuracy}')\n",
    "        \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "unflatten: Provided sizes [128, 1, 1] don't multiply up to the size of dim 1 (64) in the input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m model \u001b[38;5;241m=\u001b[39m DecoderOnly()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     85\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device) \n\u001b[1;32m---> 86\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[7], line 80\u001b[0m, in \u001b[0;36mDecoderOnly.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 80\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "Cell \u001b[1;32mIn[7], line 66\u001b[0m, in \u001b[0;36mDecoderOnly.encoder\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# for _ in range(self.steps):\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     vfe \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(pred, x, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     68\u001b[0m     dones \u001b[38;5;241m=\u001b[39m (dones \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(prev_vfe \u001b[38;5;241m-\u001b[39m vfe \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m))\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\nn\\modules\\flatten.py:139\u001b[0m, in \u001b[0;36mUnflatten.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflattened_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\_tensor.py:1189\u001b[0m, in \u001b[0;36mTensor.unflatten\u001b[1;34m(self, dim, sizes)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39munflatten(dim, sizes, names)\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msizes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: unflatten: Provided sizes [128, 1, 1] don't multiply up to the size of dim 1 (64) in the input tensor"
     ]
    }
   ],
   "source": [
    "class DecoderOnly(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.z_dim = 128\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(1, (self.z_dim, 1, 1)),\n",
    "            nn.ConvTranspose2d(self.z_dim, 64, 4, 2, 0),\n",
    "            # nn.ReLU(),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 2),\n",
    "            nn.BatchNorm2d(32)\n",
    "            nn.Dropout(0.2),\n",
    "            # nn.ReLU(),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(32, 16, 5, 2, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(16, 1, 6, 2, padding=1),\n",
    "\n",
    "            # nn.Linear(128, 256),\n",
    "            # nn.ELU(),\n",
    "            # nn.Linear(256, 512),\n",
    "            # nn.Linear(512, 784),\n",
    "            # nn.Linear(128, 784),\n",
    "            # nn.Unflatten(1, (1, 28, 28)),\n",
    "            nn.Sigmoid(),\n",
    "            # nn.ELU(),\n",
    "            # nn.Linear(128, 784),\n",
    "            # nn.Unflatten(1, (1, 28, 28)),\n",
    "        )\n",
    "        self.steps = 1000\n",
    "        self.gamma = 1.0\n",
    "\n",
    "    def step(self, x, z, optimiser):\n",
    "        pred = self.decoder(z)\n",
    "        vfe = F.mse_loss(pred, x)\n",
    "        optimiser.zero_grad(set_to_none=True)\n",
    "        vfe.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "    def step_no_optim(self, x, z):\n",
    "        pred = self.decoder(z)\n",
    "        vfe = F.mse_loss(pred, x)\n",
    "        z.grad = None\n",
    "        vfe.backward()\n",
    "        z = z - z.grad * 1e-3\n",
    "\n",
    "\n",
    "    def update_gamma(self, gamma, prev_vfe, vfe):\n",
    "        gamma = torch.where(vfe > prev_vfe, gamma * 0.9, gamma)\n",
    "        vfe = torch.where(vfe < prev_vfe, vfe, prev_vfe)\n",
    "        return gamma, vfe\n",
    "\n",
    "    def encoder(self, x):\n",
    "        z = torch.randn(x.shape[0], 64, device=x.device, requires_grad=True)\n",
    "        optimiser = torch.optim.AdamW([z], lr=1.0)\n",
    "        dones = torch.zeros(x.shape[0], device=x.device)\n",
    "        prev_vfe = torch.ones(x.shape[0], device=x.device) * 1e6\n",
    "        gammas = torch.ones(x.shape[0], device=x.device) * self.gamma\n",
    "        i = 0\n",
    "        while dones.sum() < x.shape[0]:\n",
    "            if i > self.steps:\n",
    "                print('Max steps reached')\n",
    "                break\n",
    "\n",
    "        # for _ in range(self.steps):\n",
    "\n",
    "            pred = self.decoder(z)\n",
    "            vfe = F.mse_loss(pred, x, reduction='none').mean(dim=(1, 2, 3))\n",
    "            dones = (dones + torch.where(prev_vfe - vfe < 0.1, 1.0, 0.0)).clamp(0.0, 1.0)\n",
    "            gammas, prev_vfe = self.update_gamma(gammas, prev_vfe, vfe)\n",
    "            loss = (vfe * gammas).mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            optimiser.zero_grad(set_to_none=True)\n",
    "\n",
    "            i += 1\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x = self.decoder(z)\n",
    "        return x\n",
    "    \n",
    "model = DecoderOnly().to(device)\n",
    "x = torch.randn(10, 1, 28, 28).to(device) \n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10000]:   0%|          | 2/10000 [00:01<1:37:43,  1.71it/s, train_loss=0.72, val_loss=0.72] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Val accuracy: 0.10025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [102/10000]:   1%|          | 102/10000 [00:19<56:02,  2.94it/s, train_loss=0.367, val_loss=0.362]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 Val accuracy: 0.5746666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [202/10000]:   2%|▏         | 202/10000 [00:37<55:51,  2.92it/s, train_loss=0.255, val_loss=0.242]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200 Val accuracy: 0.7936666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [302/10000]:   3%|▎         | 302/10000 [00:56<55:11,  2.93it/s, train_loss=0.199, val_loss=0.183]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300 Val accuracy: 0.84525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [402/10000]:   4%|▍         | 402/10000 [01:14<54:22,  2.94it/s, train_loss=0.156, val_loss=0.142]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400 Val accuracy: 0.8765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [502/10000]:   5%|▌         | 502/10000 [01:32<53:58,  2.93it/s, train_loss=0.128, val_loss=0.117]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 Val accuracy: 0.8961666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [602/10000]:   6%|▌         | 602/10000 [01:51<54:26,  2.88it/s, train_loss=0.112, val_loss=0.103]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600 Val accuracy: 0.9003333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [702/10000]:   7%|▋         | 702/10000 [02:09<54:06,  2.86it/s, train_loss=0.107, val_loss=0.0989]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700 Val accuracy: 0.89875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                         \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# criterion = F.binary_cross_entropy_with_logits\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# criterion = F.mse_loss\u001b[39;00m\n\u001b[0;32m      5\u001b[0m criterion \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy\n\u001b[1;32m----> 7\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 49\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_set, val_set, criterion, n_epochs)\u001b[0m\n\u001b[0;32m     46\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m model\u001b[38;5;241m.\u001b[39mstep(x_val, z_val, z_val_optimiser)\n\u001b[0;32m     51\u001b[0m x_hat \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecoder(z_val)\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2291\u001b[0m, in \u001b[0;36mModule.eval\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2288\u001b[0m         module\u001b[38;5;241m.\u001b[39mtrain(mode)\n\u001b[0;32m   2289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m-> 2291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m: T) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m   2292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sets the module in evaluation mode.\u001b[39;00m\n\u001b[0;32m   2293\u001b[0m \n\u001b[0;32m   2294\u001b[0m \u001b[38;5;124;03m    This has any effect only on certain modules. See documentations of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2305\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[0;32m   2306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "\n",
    "# criterion = F.binary_cross_entropy_with_logits\n",
    "# criterion = F.mse_loss\n",
    "criterion = F.binary_cross_entropy\n",
    "\n",
    "train_losses, val_losses = train(model, train_set, val_set, criterion, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26d687d6c90>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26d6259f010>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_losses, label='Validation Loss')\n",
    "# plt.plot(ae_val_losses, label='AE Validation Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "unflatten: Provided sizes [1, 28, 28] don't multiply up to the size of dim 1 (64) in the input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(idxs):\n\u001b[0;32m      6\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m test_set[idx]\n\u001b[1;32m----> 7\u001b[0m     x_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     axes[\u001b[38;5;241m0\u001b[39m, i]\u001b[38;5;241m.\u001b[39mimshow(x\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu(), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m     axes[\u001b[38;5;241m1\u001b[39m, i]\u001b[38;5;241m.\u001b[39mimshow(x_hat\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach(), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[53], line 82\u001b[0m, in \u001b[0;36mDecoderOnly.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 82\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z)\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "Cell \u001b[1;32mIn[53], line 68\u001b[0m, in \u001b[0;36mDecoderOnly.encoder\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# for _ in range(self.steps):\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     vfe \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(pred, x, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     70\u001b[0m     dones \u001b[38;5;241m=\u001b[39m (dones \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(prev_vfe \u001b[38;5;241m-\u001b[39m vfe \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m))\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\nn\\modules\\flatten.py:139\u001b[0m, in \u001b[0;36mUnflatten.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflattened_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\_tensor.py:1189\u001b[0m, in \u001b[0;36mTensor.unflatten\u001b[1;34m(self, dim, sizes)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39munflatten(dim, sizes, names)\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msizes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: unflatten: Provided sizes [1, 28, 28] don't multiply up to the size of dim 1 (64) in the input tensor"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 40 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_size = 20\n",
    "idxs = torch.randint(0, len(test_set), (sample_size,))\n",
    "\n",
    "fig, axes = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "for i, idx in enumerate(idxs):\n",
    "    x, _ = test_set[idx]\n",
    "    x_hat = model(x.unsqueeze(0))\n",
    "    axes[0, i].imshow(x.squeeze().cpu(), cmap='gray')\n",
    "    axes[1, i].imshow(x_hat.squeeze().cpu().detach(), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_1kmnist(\n",
    "        model,\n",
    "        train_set,\n",
    "        val_set,\n",
    "        n_epochs,\n",
    "        batch_size,\n",
    "):\n",
    "    classifier = nn.Linear(64, 10).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimiser = torch.optim.AdamW(classifier.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for _, (x, label) in loop:\n",
    "            if epoch > 0:\n",
    "                loop.set_description(f'Epoch [{epoch}/{n_epochs}]')\n",
    "                loop.set_postfix(train_loss=train_losses[-1], val_loss=val_losses[-1], val_acc=val_accs[-1])\n",
    "\n",
    "            x = model.encoder(x)\n",
    "            pred = classifier(x)\n",
    "            loss = criterion(pred, label)\n",
    "\n",
    "            optimiser.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            train_loss += loss.item()\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        num_correct = 0\n",
    "        for x, label in val_loader:\n",
    "            x = model.encoder(x)\n",
    "            pred = classifier(x)\n",
    "            loss = criterion(pred, label)\n",
    "            val_loss += loss.item()\n",
    "            num_correct += (pred.argmax(1) == label).sum().item()\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accs.append(num_correct / len(val_set) * 100)\n",
    "        \n",
    "    return train_losses, val_losses, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m c_t_losses, c_v_losses, c_v_accs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_1kmnist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[66], line 28\u001b[0m, in \u001b[0;36mtrain_1kmnist\u001b[1;34m(model, train_set, val_set, n_epochs, batch_size)\u001b[0m\n\u001b[0;32m     25\u001b[0m     loop\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m     loop\u001b[38;5;241m.\u001b[39mset_postfix(train_loss\u001b[38;5;241m=\u001b[39mtrain_losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], val_loss\u001b[38;5;241m=\u001b[39mval_losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], val_acc\u001b[38;5;241m=\u001b[39mval_accs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m pred \u001b[38;5;241m=\u001b[39m classifier(x)\n\u001b[0;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred, label)\n",
      "Cell \u001b[1;32mIn[61], line 62\u001b[0m, in \u001b[0;36mDecoderOnly.encoder\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     59\u001b[0m gammas, prev_vfe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_gamma(gammas, prev_vfe, vfe)\n\u001b[0;32m     60\u001b[0m loss \u001b[38;5;241m=\u001b[39m (vfe \u001b[38;5;241m*\u001b[39m gammas)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m---> 62\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     64\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c_t_losses, c_v_losses, c_v_accs = train_1kmnist(model, train_set, val_set, EPOCHS, 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
