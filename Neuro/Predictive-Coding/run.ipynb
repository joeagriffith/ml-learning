{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48f108b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joe\\anaconda3\\envs\\ml-env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from PCCNNv4 import PCCNNModel\n",
    "from CNN import CNNModel\n",
    "from CustomDataset import LoadFromFolder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa8d1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5c6c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7258ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 1024\n",
    "# train_dataset = datasets.MNIST(root='../../datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "# train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "# test_dataset = datasets.MNIST(root='../../datasets/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "# test_loader = DataLoader(dataset=test_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "# INPUT_CHANNELS = 1\n",
    "# NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0a4e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 500\n",
    "# train_val_dataset = datasets.CIFAR10(root='../../datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [45000, 5000])\n",
    "# train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "# val_loader = DataLoader(dataset=val_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "# test_dataset = datasets.CIFAR10(root='../../datasets/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "# test_loader = DataLoader(dataset=test_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "# INPUT_CHANNELS = 3\n",
    "# NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ef62f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size).item())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaefe8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimiser, criterion, model_name, num_epochs, flatten=False, cross_val=False, log_dir=\"logs\"):\n",
    "    writer = SummaryWriter(f\"{log_dir}/{model_name}_Epochs{num_epochs}_BS{BATCH_SIZE}_LR{LEARNING_RATE}_WD{WEIGHT_DECAY}_\")\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    train_e_mag = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    val_e_mag = []\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_val_loss = 99999999.9\n",
    "\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_dataset.apply_transform()\n",
    "        \n",
    "        train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "        loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)    \n",
    "\n",
    "        num_correct = 0\n",
    "        total_train_loss = 0\n",
    "        total_train_e_mag = 0\n",
    "\n",
    "        for batch_idx, (images, y) in loop:\n",
    "            x = images.to(device)\n",
    "            if flatten:\n",
    "                x = torch.flatten(x, start_dim=1)\n",
    "            target = y.to(device)\n",
    "            out = model(x)\n",
    "\n",
    "            loss = criterion(out[0], target)\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                total_train_loss += loss.item()\n",
    "                total_train_e_mag += out[1]\n",
    "\n",
    "                prediction = torch.argmax(out[0], dim=1)\n",
    "                batch_correct = (prediction == y.to(device)).sum().item()\n",
    "                num_correct += batch_correct\n",
    "                n = x.shape[0]\n",
    "\n",
    "                if epoch > 0:\n",
    "                    loop.set_description(f\"Epoch [{epoch}/{num_epochs}]\")\n",
    "                    loop.set_postfix(\n",
    "                        train_loss = train_loss[-1], \n",
    "                        train_acc = train_acc[-1], \n",
    "                        val_loss = val_loss[-1], \n",
    "                        val_acc = val_acc[-1][0],\n",
    "                    )\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            train_loss.append(total_train_loss / len(train_loader))\n",
    "            train_acc.append(num_correct * 100.0 / len(train_dataset))\n",
    "            train_e_mag.append(total_train_e_mag / len(train_loader))\n",
    "\n",
    "            val_correct = 0\n",
    "            val_n = 0\n",
    "            total_val_loss = 0\n",
    "            total_val_acc = torch.zeros(3)\n",
    "            total_val_e_mag = 0\n",
    "\n",
    "            for batch_idx, (images, y) in enumerate(val_loader):\n",
    "                x = images.to(device)\n",
    "                if flatten:\n",
    "                    x = torch.flatten(x, start_dim=1)\n",
    "                target = y.to(device)\n",
    "                out = model(x)\n",
    "                total_val_loss += criterion(out[0], target).item()\n",
    "                total_val_acc += torch.tensor(topk_accuracy(out[0], target, (1,3,5)))\n",
    "                total_val_e_mag += out[1]\n",
    "                \n",
    "            val_loss.append(total_val_loss / len(val_loader))\n",
    "            val_acc.append((total_val_acc / len(val_loader)).tolist())    \n",
    "            val_e_mag.append(total_val_e_mag / len(val_loader))\n",
    "                \n",
    "#             if best_val_acc < val_acc[-1][0]:\n",
    "#                 best_val_acc = val_acc[-1][0]\n",
    "#                 torch.save(model.state_dict(), f'models/{model_name}.pth')\n",
    "                \n",
    "            if best_val_loss > val_loss[-1]:\n",
    "                best_val_loss = val_loss[-1]\n",
    "                torch.save(model.state_dict(), f'models/{model_name}.pth')\n",
    "\n",
    "            step = epoch * len(train_dataset)\n",
    "            writer.add_scalar(\"Training Loss\", train_loss[-1], step)\n",
    "            writer.add_scalar(\"Training Accuracy\", train_acc[-1], step)\n",
    "            writer.add_scalar(\"Training E_mag\", train_e_mag[-1], step)\n",
    "            writer.add_scalar(\"Validation Loss\", val_loss[-1], step)\n",
    "            writer.add_scalar(\"Validation Accuracy Top1\", val_acc[-1][0], step)\n",
    "            writer.add_scalar(\"Validation E_mag\", val_e_mag[-1], step)\n",
    "            writer.add_scalar(\"Validation Accuracy Top3\", val_acc[-1][1], step)\n",
    "            writer.add_scalar(\"Validation Accuracy Top5\", val_acc[-1][2], step)\n",
    "            \n",
    "            \n",
    "            model.train()\n",
    "    return np.array(train_loss), np.array(train_acc), np.array(val_loss), np.array(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71186e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomGaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std=0.001):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        noise = (torch.randn(img.shape) * self.std + self.mean)\n",
    "        if img.is_cuda:\n",
    "            noise = noise.to(\"cuda\")\n",
    "        return img + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdb38aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_arr = [\n",
    "    transforms.Compose([ \n",
    "#         transforms.ToTensor(), \n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomAffine(degrees=90, translate=(0.15,0.15), scale=(0.8,1.2))]),\n",
    "    transforms.Compose([ \n",
    "#         transforms.ToTensor(), \n",
    "        transforms.RandomHorizontalFlip(p=0.5), \n",
    "        transforms.ColorJitter(hue=0.015, saturation=0.015, brightness=0.015)]),\n",
    "    transforms.Compose([ \n",
    "#         transforms.ToTensor(), \n",
    "        transforms.RandomHorizontalFlip(p=0.5), \n",
    "        transforms.GaussianBlur((5,5), sigma=(0.01, 0.75))]),\n",
    "    transforms.Compose([ \n",
    "#         transforms.ToTensor(), \n",
    "        transforms.RandomHorizontalFlip(p=0.5), \n",
    "        transforms.RandomErasing(scale=(0.02, 0.3))]),\n",
    "    transforms.Compose([ \n",
    "#         transforms.ToTensor(), \n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        RandomGaussianNoise()])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33ae375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 150\n",
    "INPUT_SHAPE = (3,64,64)\n",
    "NUM_CLASSES = 30\n",
    "VAL_RATIO = 0.2\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY=3e-2\n",
    "NUM_EPOCHS=100\n",
    "FEATURES=16\n",
    "\n",
    "dataset = LoadFromFolder('..\\\\..\\\\..\\\\datasets\\\\TinyImageNet30\\\\train_set\\\\train_set', \n",
    "                         (0,INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2]), \n",
    "                         transform=transform_arr[0],\n",
    "                         shuffle=False,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d1c9cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800\n",
      "2700\n",
      "<class 'PCCNNv4.PCCNNModel'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19332\\3909619716.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mcross_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"logs_pccnnv4\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     )\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19332\\2667162035.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimiser, criterion, model_name, num_epochs, flatten, cross_val, log_dir)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joe\\anaconda3\\envs\\ml-env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joe\\Documents\\ML-Learning\\Neuro\\Predictive-Coding\\PCCNNv4.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, target, calc_e_mag)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpc_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mlayer_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_vars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_e\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joe\\Documents\\ML-Learning\\Neuro\\Predictive-Coding\\PCCNNv4.py\u001b[0m in \u001b[0;36minit_vars\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_vars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_arr, train_acc_arr, val_loss_arr, val_acc_arr = [], [], [], [] \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for i in range(1):\n",
    "    train_dataset, val_dataset = dataset.cross_val_split_by_class(VAL_RATIO, i, device=\"cpu\")\n",
    "    # train_dataset.transform = transform_arr[i]\n",
    "    print(len(train_dataset))\n",
    "    print(len(val_dataset))\n",
    "    train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    model_name = f\"PCCNNv4_{str(FEATURES)}_{i}\"\n",
    "    model = PCCNNModel(FEATURES, INPUT_SHAPE, NUM_CLASSES, device=\"cpu\")\n",
    "    model.to(device)\n",
    "    print(type(model))\n",
    "    optimiser = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    train_loss, train_acc, val_loss, val_acc = train(\n",
    "        model, \n",
    "        optimiser, \n",
    "        criterion, \n",
    "        model_name, \n",
    "        num_epochs=NUM_EPOCHS, \n",
    "        cross_val=True,\n",
    "        log_dir=\"logs_pccnnv4\"\n",
    "    )\n",
    "    \n",
    "    train_loss_arr.append(train_loss)\n",
    "    train_acc_arr.append(train_acc)\n",
    "    val_loss_arr.append(val_loss)\n",
    "    val_acc_arr.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04a739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a96253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12f8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b9a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "def test():\n",
    "    \n",
    "    N, inp_channels, H, W, NUM_CLASSES = 8, 3, 32, 32, 10\n",
    "    z_dim = 100\n",
    "    x = torch.randn((N, inp_channels, H, W)).to(device)\n",
    "    cnn = CNNModel().to(device)\n",
    "    initialize_weights(cnn)\n",
    "    assert cnn(x)[0].shape == (N,10)\n",
    "    \n",
    "    pccnn = PCModel().to(device)\n",
    "    initialize_weights(pccnn)\n",
    "    assert pccnn(x)[0].shape == (N,10)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98121122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, with_targets=False):\n",
    "    model.eval()\n",
    "    n = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, y) in enumerate(test_loader):\n",
    "#         x = data[:,:,:27,:27].to(device)\n",
    "        x = data.to(device)\n",
    "        batch_size = data.shape[0]\n",
    "        n = n + batch_size\n",
    "        target = None\n",
    "        if with_targets:\n",
    "            target = F.one_hot(y).unsqueeze(2).unsqueeze(3).to(device)\n",
    "        out = model(x, target)\n",
    "        output = torch.argmax(out[0], dim=1)\n",
    "        y = y.to(device)\n",
    "        batch_correct = output == y\n",
    "        correct = correct + batch_correct.sum()\n",
    "\n",
    "    print(f'Test Accuracy: {correct/n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f118f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('PC-RB_Conv2D-V2.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1319727",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'PCCNN_ignore-emag'\n",
    "writer = SummaryWriter(f\"logs/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57656792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 3e-4\n",
    "NUM_EPOCHS = 100\n",
    "WEIGHT_DECAY = 0.02\n",
    "\n",
    "# optimiser = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "optimiser = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "n = 0\n",
    "correct = 0\n",
    "val_loss = 0\n",
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS, NUM_EPOCHS*2):\n",
    "    \n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_batches = 0\n",
    "    train_emag = 0\n",
    "    \n",
    "    for batch_idx, (data, y) in loop:\n",
    "#         x = data[:,:,:27,:27].to(device)\n",
    "        x = data.to(device)\n",
    "        target = F.one_hot(y).double().to(device)\n",
    "        out = model(x)\n",
    "        loss = criterion(out[0], target)\n",
    "#         if len(out) > 1:\n",
    "#             loss += out[1]\n",
    "        \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = torch.argmax(out[0], dim=1)\n",
    "            arg_correct = output == y.to(device)\n",
    "            correct = correct + arg_correct.sum()\n",
    "            n = n + x.shape[0]\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_batches += 1\n",
    "            if len(out) > 1:\n",
    "                train_emag += out[1].item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            loop.set_description(f\"Epoch [{epoch}/{NUM_EPOCHS}]\")\n",
    "            loop.set_postfix(loss = loss.item(), val_loss = val_loss, train_acc=(correct/n).item())\n",
    "    \n",
    "    # Calculate validation_acc\n",
    "    with torch.no_grad():\n",
    "        val_emag = 0\n",
    "        val_n = 0\n",
    "        val_correct = 0\n",
    "        val_batches = 0\n",
    "        for batch_idx, (data, y) in enumerate(val_loader):\n",
    "            x = data.to(device)\n",
    "            batch_size = data.shape[0]\n",
    "            val_n += batch_size\n",
    "            out = model(x)\n",
    "            output = torch.argmax(out[0], dim=1)\n",
    "            y = y.to(device)\n",
    "            batch_correct = output == y\n",
    "            val_correct += batch_correct.sum()\n",
    "            if len(out) > 1:\n",
    "                val_emag += out[1].item()\n",
    "            val_batches += 1\n",
    "            \n",
    "        train_loss /= train_batches\n",
    "        val_acc = val_correct/val_n\n",
    "        \n",
    "        # Update logs\n",
    "        writer.add_scalar('training loss', train_loss, epoch*train_batches*BATCH_SIZE)\n",
    "        writer.add_scalar('validation accuracy', val_acc, epoch*train_batches*BATCH_SIZE)\n",
    "        \n",
    "        if len(out) > 1:\n",
    "            train_emag /= train_batches\n",
    "            val_emag /= val_batches\n",
    "            writer.add_scalar('training emag', train_emag, epoch*train_batches*BATCH_SIZE)\n",
    "            writer.add_scalar('validation emag', val_emag, epoch*train_batches*BATCH_SIZE)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a57c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554338cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'PC-RB_Conv2D-V2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df101a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 3e-7\n",
    "NUM_EPOCHS = 5\n",
    "optimiser = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "mean_loss = 0\n",
    "\n",
    "model.eval()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_idx, (data, y) in enumerate(train_loader):\n",
    "        x = data[:,:,:27,:27].to(device)\n",
    "        out = model(x)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f5ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 1, 5,1, 9, 5, 8, 0, 2, 6, 5, 8, 2])\n",
    "x = F.argmax(x)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ebc7c8a3c5c4a81c6d3df3c7c091e8d1ec5b9d2aff4d30dfde49ec05d4a72c2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
