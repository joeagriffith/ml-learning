{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joe\\anaconda3\\envs\\ml-env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from cnn_models import LeNet\n",
    "from PCLeNet import PCLeNet, PCLeNetv3, PCLeNetv3Deep\n",
    "from PCLeNet_L1MoreFeatures import PCLeNetv2\n",
    "from CustomDataset import PreloadedDataset\n",
    "from train_loops import train, train_pc_classification, train_pc_error, train_pc_ec\n",
    "from my_funcs import RandomGaussianNoise, Scale\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "VAL_RATIO = 0.2\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # Scale(255.0),\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),\n",
    "    RandomGaussianNoise(std=0.001),\n",
    "    transforms.RandomAffine(degrees=20, translate=(0.15,0.15), scale=(0.90,1.10)),\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root=\"../../../datasets/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "val_len = int(len(dataset) * VAL_RATIO)\n",
    "train_len = len(dataset) - val_len\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_len, val_len])\n",
    "train_dataset = PreloadedDataset.from_dataset(train_dataset, transform, device)\n",
    "val_dataset = PreloadedDataset.from_dataset(val_dataset, transforms.ToTensor(), device)\n",
    "INPUT_SHAPE = train_dataset[0][0].shape\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 3, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Conv2d(2, 8, (3,3))\n",
    "layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                     \r"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "#  Standard LeNet CNN\n",
    "model_name = \"LeNet\"\n",
    "LEARNING_RATE = 3e-3\n",
    "lenet = LeNet(INPUT_SHAPE[0], NUM_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.AdamW(lenet.parameters(), lr=LEARNING_RATE)\n",
    "cnn_train_loss, cnn_train_acc, cnn_val_loss, cnn_val_acc, step = train(\n",
    "    lenet,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    optimiser,\n",
    "    criterion,\n",
    "    model_name,\n",
    "    150,\n",
    "    batch_size=300,\n",
    "    save_model=True,\n",
    "    model_dir=\"MNIST/models/\",\n",
    "    log_dir=\"MNIST/logs/\",\n",
    "    device=device,\n",
    "    step=7200000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [10, 84]], which is output 0 of AsStridedBackward0, is at version 3; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22380\\1605490316.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0msave_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mbest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\Joe\\Documents\\ML-Learning\\Neuro\\Predictive-Coding\\train_loops.py\u001b[0m in \u001b[0;36mtrain_pc_ec\u001b[1;34m(model, train_dataset, val_dataset, criterion, model_name, num_epochs, pc_learning_rate, pc_weight_decay, c_learning_rate, c_weight_decay, optimiser, flatten, model_dir, log_dir, step, best, save_model, batch_size, plot_err, lambdas, device)\u001b[0m\n\u001b[0;32m    566\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m                 \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlayer_loss_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m                 \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m                 \u001b[0mtrain_err\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m                 \u001b[0mtrain_mean_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joe\\anaconda3\\envs\\ml-env\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joe\\anaconda3\\envs\\ml-env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [10, 84]], which is output 0 of AsStridedBackward0, is at version 3; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "#  Standard LeNet CNN\n",
    "model_name = f\"PCLeNetv3_err\"\n",
    "LEARNING_RATE = 3e-4\n",
    "lenet = PCLeNetv3(INPUT_SHAPE, NUM_CLASSES, relu_errs=True).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.AdamW(lenet.parameters(), lr=LEARNING_RATE)\n",
    "step = train_pc_ec(\n",
    "    lenet,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    # optimiser,\n",
    "    criterion,\n",
    "    model_name,\n",
    "    500,\n",
    "    batch_size=300,\n",
    "    log_dir=\"MNIST/logs/\",\n",
    "    model_dir=\"MNIST/models\",\n",
    "    save_model=True,\n",
    "    device=device,\n",
    "    best=\"acc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_name = \"PCLeNetv3_classification\"\n",
    "lenet = PCLeNetv3(INPUT_SHAPE, NUM_CLASSES, relu_errs=True).to(device)\n",
    "lenet.load_state_dict(torch.load(f\"MNIST/models/{model_name}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAHWCAYAAACBsnu3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAamklEQVR4nO3daYyV5fk/8Gt2YASUsYpVAYsLJTWaGqq2IjQVsAHjQiUajGujptYtNa2NQVATNaY2WmPRFyAuaLWUuqQJKEXbprEY10YxaQRHbSq4RA0FWc7M83/hHwI/eKZnBg4D13w+ybyYcz3Lfc48ub5zz5z7PHVFURQBAOzV6nt7AADAzhPoAJCAQAeABAQ6ACQg0AEgAYEOAAkIdABIQKADQAICHQASEOhVmjdvXtTV1UV7e3u39501a1bU1dXFJ598ssvGs/mYtfTQQw/FOeecE0cddVTU19fHiBEjano+4Ct9sd+MGDEi6urqtvu6/PLLa3reTBp7ewDsuR5++OFYtWpVfOc734nOzs7YtGlTbw8JSOx73/te/OpXv9rmsQMPPLCXRrP3EeiUWrx4cdTXf/VHnClTpsSbb77ZyyMCMtt3333jhBNO6O1h7LX8yX0nPPfcc3H66afHIYccEv369YvDDz88LrvsstI/dX3wwQdx1llnxaBBg2Lw4MFx3nnnxccff7zddo8//niceOKJ0draGvvss09MmjQpXnvttf85nqVLl8b48eOjra0t+vfvH8OGDYupU6fGunXrevT8Noc50Puy9xt2no69E1asWBEnnnhizJ49O5599tm48cYbY9myZXHSSSft8M/TZ555Zhx++OGxYMGCmDVrVjz55JMxadKkbba99dZb49xzz43Ro0fHE088EQ8//HCsWbMmxo4dG8uXLy8dS3t7e0yePDmam5tj7ty5sWjRorj99tujtbU1Nm7cuGW7Cy+8sMf/mwN6T1/oN3/9619j4MCB0dTUFKNHj44777wzOjo6qn+R+rqCqjzwwANFRBTvvvvuDuudnZ3Fpk2bivfee6+IiOKpp57aUps5c2YREcW11167zT7z588vIqJ45JFHiqIoivfff79obGwsrrzyym22W7NmTTF06NBi2rRp2x1zswULFhQRUbz++utdPo+LL764aGhoKNrb26t63ptNnjy5GD58eLf2AXqmL/abn/zkJ8XcuXOLv/zlL8WTTz5ZTJ8+vYiI4rzzzvuf+/IVM/Sd8NFHH8Xll18ehx56aDQ2NkZTU1MMHz48IiLefvvt7bafPn36Nt9PmzYtGhsb4/nnn4+Ir/5nXalU4vzzz49KpbLlq1+/fjFu3Lh44YUXSsdy7LHHRnNzc1x66aXx4IMPxsqVK3e43Zw5c6JSqWwZJ7B3yN5v7r333rjooovi5JNPjtNPPz0eeeSR+OlPfxqPPPJIVf8CwJ/ce6yzszMmTpwYCxcujJ///Ofx5z//OV566aX4xz/+ERERX3755Xb7DB06dJvvGxsbo62tLT799NOIiFi9enVERIwZMyaampq2+Xr88ce7XIYycuTIWLJkSRxwwAFxxRVXxMiRI2PkyJFx991376qnDPSSvtpvzjvvvIiILc+TrnmXew+9+eab8cYbb8S8efPiggsu2PL4O++8U7rPqlWr4uCDD97yfaVSiU8//TTa2toiImL//fePiIgFCxb0aAY9duzYGDt2bHR0dMTLL78c99xzT1xzzTVx4IEHxjnnnNPt4wF7hr7ab4qiiAhv0K2WQO+hzR+y0NLSss3j999/f+k+8+fPj+OOO27L90888URUKpUYP358RERMmjQpGhsbY8WKFTF16tQej62hoSGOP/74GDVqVMyfPz9effVVgQ57sb7abx566KGICEvZqiTQe2jUqFExcuTIuP7666MoihgyZEg888wz8dxzz5Xus3DhwmhsbIwJEybEW2+9FTNmzIhjjjkmpk2bFhFffVLSzTffHDfccEOsXLkyTj311Nhvv/1i9erV8dJLL0Vra2vcdNNNOzz2fffdF0uXLo3JkyfHsGHDYv369TF37tyIiDjllFO2bHfJJZfEgw8+GCtWrPifv5UvX758yztdV61aFevWrYsFCxZERMTo0aNj9OjR1b9gQI9l7zePPvpoLFy4MCZPnhzDhw+Pzz//PH7/+9/H7373u7jwwgvjmGOO6cnL1vf08pvy9ho7etfp8uXLiwkTJhQDBw4s9ttvv+Lss88u3n///SIiipkzZ27ZbvM7RF955ZXitNNOK/bZZ59i4MCBxbnnnlusXr16u3M9+eSTxfe///1i0KBBRUtLSzF8+PDiRz/6UbFkyZLtjrnZiy++WJx55pnF8OHDi5aWlqKtra0YN25c8fTTT29z7AsuuKDLd89ubfM5dvS19fMDdq2+1m9efPHF4gc/+EExdOjQoqmpqRgwYEAxZsyY4re//W3R0dHRvRevD6sriv//TwoAYK/lnQYAkIBAB4AEBDoAJCDQASABgQ4ACQh0AEhAoANAAlV/UtwZZ5xRWnvqqadKa7fddltp7aCDDiqtbf2Rhf/X4MGDS2tdLavf/PGJPVGr4+7teuO5NzQ0lNa6+jlt2LChtHbLLbeU1q677rrSmk/Lqw39Rr/ZEf2m635jhg4ACQh0AEhAoANAAgIdABIQ6ACQQNV3W1u8eHFpbdOmTaW1KVOmdH9UQJ+m30D3maEDQAICHQASEOgAkIBAB4AEBDoAJCDQASCBqm/O8sUXX5TW2tvbS2sjRoworbW2tpbWDjvssGqGBbtER0dHaa2rmzNQG/oNmdWq35ihA0ACAh0AEhDoAJCAQAeABAQ6ACQg0AEggaqXrXV1U7auamvXri2tDRgwoNrTQ01t3LixtNa/f//dOBIi9Btyq1W/MUMHgAQEOgAkINABIAGBDgAJCHQASECgA0ACVS9bGzx4cGmtubm5tNbS0tKj/WB3smxtz6LfkJllawBAKYEOAAkIdABIQKADQAICHQASEOgAkEDVy9YaGhpKa5VKpbTW2dnZo2PC7lRf73fbPYl+Q2a16je6GAAkINABIAGBDgAJCHQASECgA0ACAh0AEqh62dq6detKa10tFelqiUlHR0e1p4eaci3uWfQbMqvVtWiGDgAJCHQASECgA0ACAh0AEhDoAJCAQAeABHbJ3daam5vLT9BYfoqmpqZqTw81VVdX19tDYCv6DZnVqt+YoQNAAgIdABIQ6ACQgEAHgAQEOgAkINABIAGBDgAJVL0OvSv9+/cvrfV0zSjAjug3sGNm6ACQgEAHgAQEOgAkINABIAGBDgAJCHQASGCXrOPYtGlTaa2zs7O05paVQHfpN7BjZugAkIBAB4AEBDoAJCDQASABgQ4ACQh0AEig6mVrXS0HKYpil9dgd3It7ln0GzKr1bVohg4ACQh0AEhAoANAAgIdABIQ6ACQgEAHgAR2yd3WLBUBdhf9BnbMDB0AEhDoAJCAQAeABAQ6ACQg0AEgAYEOAAnskmVrPWWJCbC76DdkZ4YOAAkIdABIQKADQAICHQASEOgAkIBAB4AEBDoAJCDQASABgQ4ACQh0AEhAoANAAgIdABIQ6ACQQNV3W6urq+tRDaC79BvoPjN0AEhAoANAAgIdABIQ6ACQgEAHgAQEOgAkUPWytaIoelQD6C79BrrPDB0AEhDoAJCAQAeABAQ6ACQg0AEgAYEOAAlUvWytp7paYtLZ2Vnr0wN9iH5DX2aGDgAJCHQASECgA0ACAh0AEhDoAJCAQAeABGq+bK2+vvx3hq5qAN2l39CXucIBIAGBDgAJCHQASECgA0ACAh0AEhDoAJBA1cvW3KmIzLq6Sxe7n35DZrXqN2boAJCAQAeABAQ6ACQg0AEgAYEOAAkIdABIoOpla42N5Zs2NDSU1pqamkprzc3N1Z4easoyqT2LfkNmteo3ZugAkIBAB4AEBDoAJCDQASABgQ4ACQh0AEig6mVr9fXl2d/S0tKjWldLTGB36mopFLuffkNmteo3ZugAkIBAB4AEBDoAJCDQASABgQ4ACQh0AEig6mVrXd0dZv369aW1Dz/8sEfHPOKII6obGOwCX375ZWlt33333Y0jIUK/Ibda9RszdABIQKADQAICHQASEOgAkIBAB4AEBDoAJCDQASCBqtehd3Xrwa5uWVipVEprn3/+ebWnh5rasGFDbw+Breg3ZFarfmOGDgAJCHQASECgA0ACAh0AEhDoAJCAQAeABKpetrZx48Ye1bq6FVxbW1u1p4eaamho6O0hsBX9hsxq1W/M0AEgAYEOAAkIdABIQKADQAICHQASEOgAkEDVy9bWrl1bWhsyZEhpbeTIkaW1gQMHVnt6qKmu7u7F7qffkFmt+o0ZOgAkINABIAGBDgAJCHQASECgA0ACAh0AEqh62dr+++9fWhswYEBpzVIR9gaVSqW3h8BW9Bsyq1W/MUMHgAQEOgAkINABIAGBDgAJCHQASECgA0ACdUVRFNVs+NFHH5XWDjjggF02IAD9BrrPDB0AEhDoAJCAQAeABAQ6ACQg0AEgAYEOAAlUvWwNANhzmaEDQAICHQASEOgAkIBAB4AEBDoAJCDQASABgQ4ACQh0AEhAoANAAgIdABIQ6ACQgEAHgAQEOgAkINABIAGBDgAJCHQASECgA0ACAh0AEhDoAJCAQAeABAQ6ACQg0Ks0b968qKuri/b29m7vO2vWrKirq4tPPvlkl41n8zFr5YUXXoi6urrSr8svv7xm54a+rq/1m4iINWvWxFVXXRUHH3xwtLS0xJFHHhl33HFHdHR01PS8mTT29gDYM33729+OF198cbvHZ8+eHQ899FCceeaZvTAqIKNKpRITJkyIf/3rX3HLLbfEkUceGYsWLYrrr78+/v3vf8dvfvOb3h7iXkGgs0ODBg2KE044YZvHiqKI6dOnx/Dhw2PChAm9NDIgmwULFsSyZcviD3/4Q5x11lkRETFhwoT473//G/fee29cccUVcdRRR/XyKPd8/uS+E5577rk4/fTT45BDDol+/frF4YcfHpdddlnpn7o++OCDOOuss2LQoEExePDgOO+88+Ljjz/ebrvHH388TjzxxGhtbY199tknJk2aFK+99tr/HM/SpUtj/Pjx0dbWFv37949hw4bF1KlTY926dTv9XCMinn/++Vi5cmVcdNFFUV/v0oHdKXO/+fvf/x51dXXxwx/+cJvHp0yZEp2dnfHHP/6x28fsi3TlnbBixYo48cQTY/bs2fHss8/GjTfeGMuWLYuTTjopNm3atN32Z555Zhx++OGxYMGCmDVrVjz55JMxadKkbba99dZb49xzz43Ro0fHE088EQ8//HCsWbMmxo4dG8uXLy8dS3t7e0yePDmam5tj7ty5sWjRorj99tujtbU1Nm7cuGW7Cy+8sMf/m5szZ07U19fHRRdd1O19gZ2Tud9s3Lgx6uvro6mpaZvHW1paIiLin//8ZzUvEQVVeeCBB4qIKN59990d1js7O4tNmzYV7733XhERxVNPPbWlNnPmzCIiimuvvXabfebPn19ERPHII48URVEU77//ftHY2FhceeWV22y3Zs2aYujQocW0adO2O+ZmCxYsKCKieP3117t8HhdffHHR0NBQtLe3V/W8N/vss8+Kfv36FZMmTerWfkD39bV+c9dddxURUfztb3/b5vEZM2YUEVFMnDixy/35ihn6Tvjoo4/i8ssvj0MPPTQaGxujqakphg8fHhERb7/99nbbT58+fZvvp02bFo2NjfH8889HRMTixYujUqnE+eefH5VKZctXv379Yty4cfHCCy+UjuXYY4+N5ubmuPTSS+PBBx+MlStX7nC7OXPmRKVS2TLOas2fPz/Wr18fP/7xj7u1H7BrZO4306dPjyFDhsSll14ay5Yti88//zwee+yxLW+G8y++6nhTXA91dnbGxIkT4z//+U/MmDEjjj766GhtbY3Ozs444YQT4ssvv9xun6FDh27zfWNjY7S1tcWnn34aERGrV6+OiIgxY8bs8JxdXdQjR46MJUuWxB133BFXXHFFrF27Nr7xjW/EVVddFVdffXVPn+YWc+bMia997Wtx+umn7/SxgO7J3m/233//WLRoUVxwwQVb3ozb1tYWv/71r+OSSy6Jgw8+uNvH7IsEeg+9+eab8cYbb8S8efPiggsu2PL4O++8U7rPqlWrtrkwK5VKfPrpp9HW1hYRX13UEV+947O7M+iIiLFjx8bYsWOjo6MjXn755bjnnnvimmuuiQMPPDDOOeecbh9vs9deey1ee+21+NnPfrbd/7iA2usL/WbMmDGxfPnyaG9vj7Vr18YRRxwRr7zySkREnHzyyd0+Xl8k0Hto84csbH7Txmb3339/6T7z58+P4447bsv3TzzxRFQqlRg/fnxEREyaNCkaGxtjxYoVMXXq1B6PraGhIY4//vgYNWpUzJ8/P1599dWdCvQ5c+ZERMQll1zS42MAPdeX+s2IESMi4qtlsnfeeWd8/etfj7PPPrvHx+tLBHoPjRo1KkaOHBnXX399FEURQ4YMiWeeeSaee+650n0WLlwYjY2NMWHChHjrrbdixowZccwxx8S0adMi4qsL+eabb44bbrghVq5cGaeeemrst99+sXr16njppZeitbU1brrpph0e+7777oulS5fG5MmTY9iwYbF+/fqYO3duRESccsopW7a75JJL4sEHH4wVK1ZU9Vv5+vXr49FHH43vfve78c1vfrM7LxGwi/SFfnPDDTfE0UcfHQcddFC8//77MXfu3Fi2bFn86U9/iv79+3f3JeuTBHoPNTU1xTPPPBNXX311XHbZZdHY2BinnHJKLFmyJIYNG7bDfRYuXBizZs2K2bNnR11dXZx22mlx1113RXNz85ZtfvnLX8bo0aPj7rvvjsceeyw2bNgQQ4cOjTFjxnT5cavHHntsPPvsszFz5sxYtWpV7LPPPvGtb30rnn766Zg4ceKW7To6OqKjoyOKoqjqeS5cuDA+++wzb4aDXtQX+s1nn30Wv/jFL2LVqlUxaNCgGDduXCxbtiyOPvrobrxSfVtdUW1nBwD2WNYCAEACAh0AEhDoAJCAQAeABAQ6ACQg0AEgAYEOAAkIdABIoOpPijvjjDNKa0899VRp7bbbbiutHXTQQaW1rT+D+P8aPHhwaa2rz8nZ/HnIPVGr4+7teuO5NzQ0lNa6+jlt2LChtHbLLbeU1q677rrS2ujRo0tr9Jx+o9/siH7Tdb8xQweABAQ6ACQg0AEgAYEOAAkIdABIoOrbpy5evLi0tmnTptLalClTuj8qoE/Tb6D7zNABIAGBDgAJCHQASECgA0ACAh0AEhDoAJBA1Tdn+eKLL0pr7e3tpbURI0aU1lpbW0trhx12WDXDgl2io6OjtNbVzRmoDf2GzGrVb8zQASABgQ4ACQh0AEhAoANAAgIdABIQ6ACQQNXL1rq6KVtXtbVr15bWBgwYUO3poaY2btxYWuvfv/9uHAkR+g251arfmKEDQAICHQASEOgAkIBAB4AEBDoAJCDQASCBqpetDR48uLTW3NxcWmtpaenRfrA7Wba2Z9FvyMyyNQCglEAHgAQEOgAkINABIAGBDgAJCHQASKDqZWsNDQ2ltUqlUlrr7Ozs0TFhd6qv97vtnkS/IbNa9RtdDAASEOgAkIBAB4AEBDoAJCDQASABgQ4ACVS9bG3dunWlta6WinS1xKSjo6Pa00NNuRb3LPoNmdXqWjRDB4AEBDoAJCDQASABgQ4ACQh0AEhAoANAArvkbmvNzc3lJ2gsP0VTU1O1p4eaqqur6+0hsBX9hsxq1W/M0AEgAYEOAAkIdABIQKADQAICHQASEOgAkIBAB4AEql6H3pX+/fuX1nq6ZhRgR/Qb2DEzdABIQKADQAICHQASEOgAkIBAB4AEBDoAJLBL1nFs2rSptNbZ2Vlac8tKoLv0G9gxM3QASECgA0ACAh0AEhDoAJCAQAeABAQ6ACRQ9bK1rpaDFEWxy2uwO7kW9yz6DZnV6lo0QweABAQ6ACQg0AEgAYEOAAkIdABIQKADQAK75G5rlooAu4t+Aztmhg4ACQh0AEhAoANAAgIdABIQ6ACQgEAHgAR2ybK1nrLEBNhd9BuyM0MHgAQEOgAkINABIAGBDgAJCHQASECgA0ACAh0AEhDoAJCAQAeABAQ6ACQg0AEgAYEOAAkIdABIoOq7rdXV1fWoBtBd+g10nxk6ACQg0AEgAYEOAAkIdABIQKADQAICHQASqHrZWlEUPaoBdJd+A91nhg4ACQh0AEhAoANAAgIdABIQ6ACQgEAHgASqXrbWU10tMens7Kz16YE+RL+hLzNDB4AEBDoAJCDQASABgQ4ACQh0AEhAoANAAjVftlZfX/47Q1c1gO7Sb+jLXOEAkIBAB4AEBDoAJCDQASABgQ4ACQh0AEig6mVr7lREZl3dpYvdT78hs1r1GzN0AEhAoANAAgIdABIQ6ACQgEAHgAQEOgAkUPWytcbG8k0bGhpKa01NTaW15ubmak8PNWWZ1J5FvyGzWvUbM3QASECgA0ACAh0AEhDoAJCAQAeABAQ6ACRQ9bK1+vry7G9paelRraslJrA7dbUUit1PvyGzWvUbM3QASECgA0ACAh0AEhDoAJCAQAeABAQ6ACRQ9bK1ru4Os379+tLahx9+2KNjHnHEEdUNDHaBL7/8srS277777saREKHfkFut+o0ZOgAkINABIAGBDgAJCHQASECgA0ACAh0AEhDoAJBA1evQu7r1YFe3LKxUKqW1zz//vNrTQ01t2LCht4fAVvQbMqtVvzFDB4AEBDoAJCDQASABgQ4ACQh0AEhAoANAAlUvW9u4cWOPal3dCq6tra3a00NNNTQ09PYQ2Ip+Q2a16jdm6ACQgEAHgAQEOgAkINABIAGBDgAJCHQASKDqZWtr164trQ0ZMqS0NnLkyNLawIEDqz091FRXd/di99NvyKxW/cYMHQASEOgAkIBAB4AEBDoAJCDQASABgQ4ACVS9bG3//fcvrQ0YMKC0ZqkIe4NKpdLbQ2Ar+g2Z1arfmKEDQAICHQASEOgAkIBAB4AEBDoAJCDQASCBuqIoimo2/Oijj0prBxxwwC4bEIB+A91nhg4ACQh0AEhAoANAAgIdABIQ6ACQgEAHgASqXrYGAOy5zNABIAGBDgAJCHQASECgA0ACAh0AEhDoAJCAQAeABAQ6ACQg0AEgAYEOAAkIdABIQKADQAICHQASEOgAkIBAB4AEBDoAJPD/ALmmKaI+JADZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 0: 0.00014051437028683722\n",
      "Error 1: 0.08776825666427612\n",
      "Error 2: 0.012469873763620853\n",
      "Error 3: 0.16494876146316528\n",
      "Error 4: 0.32906079292297363\n"
     ]
    }
   ],
   "source": [
    "ys = F.one_hot(torch.tensor([1, 5, 7, 9]), 10).float().to(device)\n",
    "out = lenet.predict(ys)\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(2,2, i+1)\n",
    "    plt.imshow(out[0][i].detach().squeeze(0).to(\"cpu\"), cmap='gray')\n",
    "    ax.set_title(f\"labels: {ys[i].argmax().item()}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "for i in range(len(out[1])):\n",
    "    print(f\"Error {i}: {out[1][i].square().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lenet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26724\\3607247082.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# optimiser = optim.AdamW(lenet.parameters(), lr=LEARNING_RATE)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m step = train_pc_classification(\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mlenet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lenet' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(0)\n",
    "#  Standard LeNet CNN\n",
    "model_name = \"PCLeNetv2_classification_DataAug\"\n",
    "LEARNING_RATE = 3e-4\n",
    "lenet = PCLeNetv2(INPUT_SHAPE, NUM_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.AdamW(lenet.parameters(), lr=LEARNING_RATE)\n",
    "step = train_pc_classification(\n",
    "    lenet,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    optimiser,\n",
    "    criterion,\n",
    "    model_name,\n",
    "    500,\n",
    "    batch_size=300,\n",
    "    log_dir=\"MNIST\",\n",
    "    save_model=False,\n",
    "    device=device,\n",
    "    plot_errs=True,\n",
    "    step=step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model_name=\"PCLeNetAdamW_BS500_DataAug\"\n",
    "LEARNING_RATE = 3e-4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "pclenet = PCLeNet().to(device)\n",
    "optimiser = optim.AdamW(pclenet.parameters())\n",
    "optimiser.lr=LEARNING_RATE\n",
    "pccnn_train_loss, pccnn_train_acc, pccnn_val_loss, pccnn_val_acc, step = train_pc(\n",
    "    pclenet,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    optimiser,\n",
    "    criterion,\n",
    "    model_name,\n",
    "    100,\n",
    "    batch_size=500,\n",
    "    log_dir=\"MNIST\",\n",
    "    device=device,\n",
    "    save_model=True,\n",
    "    step=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model_name=\"PCLeNetAdamW_BS500_DataAug_LR=3e-3\"\n",
    "LEARNING_RATE = 3e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "pclenet = PCLeNet().to(device)\n",
    "optimiser = optim.AdamW(pclenet.parameters())\n",
    "optimiser.lr=LEARNING_RATE\n",
    "pccnn_train_loss, pccnn_train_acc, pccnn_val_loss, pccnn_val_acc, step = train_pc(\n",
    "    pclenet,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    optimiser,\n",
    "    criterion,\n",
    "    model_name,\n",
    "    100,\n",
    "    batch_size=500,\n",
    "    log_dir=\"MNIST\",\n",
    "    device=device,\n",
    "    save_model=True,\n",
    "    step=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model_name=\"PCLeNetAdamW_BS500_DataAug_LR=3e-3Sch2\"\n",
    "LEARNING_RATE = 3e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "pclenet = PCLeNet().to(device)\n",
    "optimiser = optim.AdamW(pclenet.parameters())\n",
    "optimiser.lr=LEARNING_RATE\n",
    "pccnn_train_loss, pccnn_train_acc, pccnn_val_loss, pccnn_val_acc, step = train_pc(\n",
    "    pclenet,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    optimiser,\n",
    "    criterion,\n",
    "    model_name,\n",
    "    30,\n",
    "    batch_size=500,\n",
    "    log_dir=\"MNIST\",\n",
    "    device=device,\n",
    "    save_model=True,\n",
    "    step=0\n",
    ")\n",
    "\n",
    "optimiser.lr=3e-4\n",
    "pccnn_train_loss, pccnn_train_acc, pccnn_val_loss, pccnn_val_acc, step = train_pc(\n",
    "    pclenet,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    optimiser,\n",
    "    criterion,\n",
    "    model_name,\n",
    "    70,\n",
    "    batch_size=500,\n",
    "    log_dir=\"MNIST\",\n",
    "    device=device,\n",
    "    save_model=True,\n",
    "    step=step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(0)\n",
    "model_name=\"PCLeNetAdamW_BS500_DataAug_LR=3e-3Sch3\"\n",
    "LEARNING_RATE = 3e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "pclenet = PCLeNet().to(device)\n",
    "optimiser = optim.AdamW(pclenet.parameters())\n",
    "optimiser.lr=LEARNING_RATE\n",
    "pccnn_train_loss, pccnn_train_acc, pccnn_val_loss, pccnn_val_acc, step = train_pc(\n",
    "    pclenet,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    optimiser,\n",
    "    criterion,\n",
    "    model_name,\n",
    "    30,\n",
    "    batch_size=500,\n",
    "    log_dir=\"MNIST\",\n",
    "    device=device,\n",
    "    save_model=True,\n",
    "    step=0\n",
    ")\n",
    "\n",
    "optimiser.lr=3e-4\n",
    "pccnn_train_loss, pccnn_train_acc, pccnn_val_loss, pccnn_val_acc, step = train_pc(\n",
    "    pclenet,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    optimiser,\n",
    "    criterion,\n",
    "    model_name,\n",
    "    30,\n",
    "    batch_size=500,\n",
    "    log_dir=\"MNIST\",\n",
    "    device=device,\n",
    "    save_model=True,\n",
    "    step=step\n",
    ")\n",
    "\n",
    "optimiser.lr=3e-5\n",
    "pccnn_train_loss, pccnn_train_acc, pccnn_val_loss, pccnn_val_acc, step = train_pc(\n",
    "    pclenet,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    optimiser,\n",
    "    criterion,\n",
    "    model_name,\n",
    "    40,\n",
    "    batch_size=500,\n",
    "    log_dir=\"MNIST\",\n",
    "    device=device,\n",
    "    save_model=True,\n",
    "    step=step\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebc7c8a3c5c4a81c6d3df3c7c091e8d1ec5b9d2aff4d30dfde49ec05d4a72c2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
